{
    "math_word_problem_generation": {
        "initial_model=gpt-4-0613": {
            "baseline_model=google/gemma-7b-it": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 63,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.4857142857142857,
                        "precision": 0.6349206349206349,
                        "recall": 0.45977011494252873,
                        "f1": 0.5333333333333333,
                        "true_negative_rate": 0.21428571428571427,
                        "false_positive_rate": 0.16428571428571428,
                        "false_negative_rate": 0.3357142857142857,
                        "true_positive_rate": 0.2857142857142857
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4857142857142857,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6349206349206349,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.45977011494252873,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.5333333333333333,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.21428571428571427,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.16428571428571428,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.3357142857142857,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.2857142857142857,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 46,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.30714285714285716,
                        "precision": 0.43478260869565216,
                        "recall": 0.22988505747126436,
                        "f1": 0.3007518796992481,
                        "true_negative_rate": 0.19285714285714287,
                        "false_positive_rate": 0.18571428571428572,
                        "false_negative_rate": 0.4785714285714286,
                        "true_positive_rate": 0.14285714285714285
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.30714285714285716,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.43478260869565216,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.22988505747126436,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.3007518796992481,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.19285714285714287,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.18571428571428572,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4785714285714286,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.14285714285714285,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 138,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.6214285714285714,
                        "precision": 0.6231884057971014,
                        "recall": 0.9885057471264368,
                        "f1": 0.7644444444444445,
                        "true_negative_rate": 0.007142857142857143,
                        "false_positive_rate": 0.37142857142857144,
                        "false_negative_rate": 0.007142857142857143,
                        "true_positive_rate": 0.6142857142857143
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6214285714285714,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6231884057971014,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.9885057471264368,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7644444444444445,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.007142857142857143,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.37142857142857144,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.007142857142857143,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.6142857142857143,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 30,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.4357142857142857,
                        "precision": 0.6333333333333333,
                        "recall": 0.21839080459770116,
                        "f1": 0.3247863247863248,
                        "true_negative_rate": 0.3,
                        "false_positive_rate": 0.07857142857142857,
                        "false_negative_rate": 0.4857142857142857,
                        "true_positive_rate": 0.1357142857142857
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4357142857142857,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6333333333333333,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.21839080459770116,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.3247863247863248,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.3,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.07857142857142857,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4857142857142857,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.1357142857142857,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 65,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.5714285714285714,
                        "precision": 0.7076923076923077,
                        "recall": 0.5287356321839081,
                        "f1": 0.6052631578947368,
                        "true_negative_rate": 0.24285714285714285,
                        "false_positive_rate": 0.1357142857142857,
                        "false_negative_rate": 0.29285714285714287,
                        "true_positive_rate": 0.32857142857142857
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5714285714285714,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7076923076923077,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5287356321839081,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.6052631578947368,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.24285714285714285,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.1357142857142857,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.29285714285714287,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.32857142857142857,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 93,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.6285714285714286,
                        "precision": 0.7096774193548387,
                        "recall": 0.7586206896551724,
                        "f1": 0.7333333333333333,
                        "true_negative_rate": 0.18571428571428572,
                        "false_positive_rate": 0.19285714285714287,
                        "false_negative_rate": 0.15,
                        "true_positive_rate": 0.4714285714285714
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6285714285714286,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7096774193548387,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.7586206896551724,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7333333333333333,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.18571428571428572,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.19285714285714287,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.15,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.4714285714285714,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 98,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.6571428571428571,
                        "precision": 0.7040816326530612,
                        "recall": 0.7931034482758621,
                        "f1": 0.745945945945946,
                        "true_negative_rate": 0.17142857142857143,
                        "false_positive_rate": 0.20714285714285716,
                        "false_negative_rate": 0.12857142857142856,
                        "true_positive_rate": 0.4928571428571429
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6571428571428571,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7040816326530612,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.7931034482758621,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.745945945945946,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.17142857142857143,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.20714285714285716,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.12857142857142856,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.4928571428571429,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-3.5-turbo-0125": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 104,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.7214285714285714,
                        "precision": 0.7307692307692307,
                        "recall": 0.8735632183908046,
                        "f1": 0.7958115183246073,
                        "true_negative_rate": 0.17857142857142858,
                        "false_positive_rate": 0.2,
                        "false_negative_rate": 0.07857142857142857,
                        "true_positive_rate": 0.5428571428571428
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.7214285714285714,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7307692307692307,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.8735632183908046,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7958115183246073,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.17857142857142858,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.2,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.07857142857142857,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.5428571428571428,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=models/gemini-1.0-pro-001": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 35,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.5,
                        "precision": 0.7428571428571429,
                        "recall": 0.2988505747126437,
                        "f1": 0.4262295081967213,
                        "true_negative_rate": 0.3142857142857143,
                        "false_positive_rate": 0.06428571428571428,
                        "false_negative_rate": 0.4357142857142857,
                        "true_positive_rate": 0.18571428571428572
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7428571428571429,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.2988505747126437,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.4262295081967213,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.3142857142857143,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.06428571428571428,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4357142857142857,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.18571428571428572,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=claude-3-opus-20240229": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 61,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.6857142857142857,
                        "precision": 0.8524590163934426,
                        "recall": 0.5977011494252874,
                        "f1": 0.7027027027027027,
                        "true_negative_rate": 0.3142857142857143,
                        "false_positive_rate": 0.06428571428571428,
                        "false_negative_rate": 0.25,
                        "true_positive_rate": 0.37142857142857144
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6857142857142857,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8524590163934426,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5977011494252874,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7027027027027027,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.3142857142857143,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.06428571428571428,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.25,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.37142857142857144,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0613": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 56,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.7357142857142858,
                        "precision": 0.9464285714285714,
                        "recall": 0.6091954022988506,
                        "f1": 0.7412587412587412,
                        "true_negative_rate": 0.35714285714285715,
                        "false_positive_rate": 0.02142857142857143,
                        "false_negative_rate": 0.24285714285714285,
                        "true_positive_rate": 0.37857142857142856
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.7357142857142858,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9464285714285714,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.6091954022988506,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7412587412587412,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.35714285714285715,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.02142857142857143,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.24285714285714285,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.37857142857142856,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0125-preview": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 58,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.7071428571428572,
                        "precision": 0.896551724137931,
                        "recall": 0.5977011494252874,
                        "f1": 0.7172413793103448,
                        "true_negative_rate": 0.3357142857142857,
                        "false_positive_rate": 0.04285714285714286,
                        "false_negative_rate": 0.25,
                        "true_positive_rate": 0.37142857142857144
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.7071428571428572,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.896551724137931,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5977011494252874,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7172413793103448,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.3357142857142857,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.04285714285714286,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.25,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.37142857142857144,
                            "stdev": 0.0
                        }
                    }
                }
            }
        },
        "initial_model=meta-llama/Llama-2-70b-chat-hf": {
            "baseline_model=google/gemma-7b-it": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 86,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.45625,
                        "precision": 0.7441860465116279,
                        "recall": 0.5,
                        "f1": 0.5981308411214953,
                        "true_negative_rate": 0.0625,
                        "false_positive_rate": 0.1375,
                        "false_negative_rate": 0.4,
                        "true_positive_rate": 0.4
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.45625,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7441860465116279,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.5981308411214953,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.0625,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.1375,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.4,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 53,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.3625,
                        "precision": 0.7547169811320755,
                        "recall": 0.3125,
                        "f1": 0.4419889502762431,
                        "true_negative_rate": 0.11875,
                        "false_positive_rate": 0.08125,
                        "false_negative_rate": 0.55,
                        "true_positive_rate": 0.25
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.3625,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7547169811320755,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.3125,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.4419889502762431,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.11875,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.08125,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.55,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.25,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 153,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.83125,
                        "precision": 0.8300653594771242,
                        "recall": 0.9921875,
                        "f1": 0.9039145907473309,
                        "true_negative_rate": 0.0375,
                        "false_positive_rate": 0.1625,
                        "false_negative_rate": 0.00625,
                        "true_positive_rate": 0.79375
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.83125,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8300653594771242,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.9921875,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.9039145907473309,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.0375,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.1625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.00625,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.79375,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 16,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.25,
                        "precision": 0.75,
                        "recall": 0.09375,
                        "f1": 0.16666666666666666,
                        "true_negative_rate": 0.175,
                        "false_positive_rate": 0.025,
                        "false_negative_rate": 0.725,
                        "true_positive_rate": 0.075
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.25,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.75,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.09375,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.16666666666666666,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.175,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.025,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.725,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.075,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 93,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.63125,
                        "precision": 0.8924731182795699,
                        "recall": 0.6484375,
                        "f1": 0.751131221719457,
                        "true_negative_rate": 0.1375,
                        "false_positive_rate": 0.0625,
                        "false_negative_rate": 0.28125,
                        "true_positive_rate": 0.51875
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.63125,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8924731182795699,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.6484375,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.751131221719457,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.1375,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.28125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.51875,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 122,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.78125,
                        "precision": 0.8934426229508197,
                        "recall": 0.8515625,
                        "f1": 0.872,
                        "true_negative_rate": 0.11875,
                        "false_positive_rate": 0.08125,
                        "false_negative_rate": 0.11875,
                        "true_positive_rate": 0.68125
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.78125,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8934426229508197,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.8515625,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.872,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.11875,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.08125,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.11875,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.68125,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 104,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.725,
                        "precision": 0.9038461538461539,
                        "recall": 0.734375,
                        "f1": 0.8103448275862069,
                        "true_negative_rate": 0.1375,
                        "false_positive_rate": 0.0625,
                        "false_negative_rate": 0.2125,
                        "true_positive_rate": 0.5875
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.725,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9038461538461539,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.734375,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.8103448275862069,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.1375,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.2125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.5875,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-3.5-turbo-0125": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 113,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.74375,
                        "precision": 0.8849557522123894,
                        "recall": 0.78125,
                        "f1": 0.8298755186721992,
                        "true_negative_rate": 0.11875,
                        "false_positive_rate": 0.08125,
                        "false_negative_rate": 0.175,
                        "true_positive_rate": 0.625
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.74375,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8849557522123894,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.78125,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.8298755186721992,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.11875,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.08125,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.175,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.625,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=models/gemini-1.0-pro-001": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 56,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.5375,
                        "precision": 0.9821428571428571,
                        "recall": 0.4296875,
                        "f1": 0.5978260869565217,
                        "true_negative_rate": 0.19375,
                        "false_positive_rate": 0.00625,
                        "false_negative_rate": 0.45625,
                        "true_positive_rate": 0.34375
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5375,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9821428571428571,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.4296875,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.5978260869565217,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.19375,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.00625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.45625,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.34375,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=claude-3-opus-20240229": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 112,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.8375,
                        "precision": 0.9553571428571429,
                        "recall": 0.8359375,
                        "f1": 0.8916666666666667,
                        "true_negative_rate": 0.16875,
                        "false_positive_rate": 0.03125,
                        "false_negative_rate": 0.13125,
                        "true_positive_rate": 0.66875
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.8375,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9553571428571429,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.8359375,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.8916666666666667,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.16875,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.03125,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.13125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.66875,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0613": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 110,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.85,
                        "precision": 0.9727272727272728,
                        "recall": 0.8359375,
                        "f1": 0.8991596638655462,
                        "true_negative_rate": 0.18125,
                        "false_positive_rate": 0.01875,
                        "false_negative_rate": 0.13125,
                        "true_positive_rate": 0.66875
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.85,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9727272727272728,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.8359375,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.8991596638655462,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.18125,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.01875,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.13125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.66875,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0125-preview": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 121,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": 0.85625,
                        "precision": 0.9338842975206612,
                        "recall": 0.8828125,
                        "f1": 0.9076305220883534,
                        "true_negative_rate": 0.15,
                        "false_positive_rate": 0.05,
                        "false_negative_rate": 0.09375,
                        "true_positive_rate": 0.70625
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 128,
                    "metrics": {
                        "accuracy": {
                            "average": 0.85625,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9338842975206612,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.8828125,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.9076305220883534,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.15,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.05,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.09375,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.70625,
                            "stdev": 0.0
                        }
                    }
                }
            }
        }
    },
    "finegrained_fact_verification": {
        "initial_model=gpt-4-0613": {
            "baseline_model=google/gemma-7b-it": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 128,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.6142857142857143,
                        "precision": 0.6328125,
                        "recall": 0.9204545454545454,
                        "f1": 0.75,
                        "true_negative_rate": 0.03571428571428571,
                        "false_positive_rate": 0.3357142857142857,
                        "false_negative_rate": 0.05,
                        "true_positive_rate": 0.5785714285714286
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6142857142857143,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6328125,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.9204545454545454,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.75,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.03571428571428571,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.3357142857142857,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.05,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.5785714285714286,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 112,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.6285714285714286,
                        "precision": 0.6607142857142857,
                        "recall": 0.8409090909090909,
                        "f1": 0.74,
                        "true_negative_rate": 0.1,
                        "false_positive_rate": 0.2714285714285714,
                        "false_negative_rate": 0.1,
                        "true_positive_rate": 0.5285714285714286
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6285714285714286,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6607142857142857,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.8409090909090909,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.74,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.1,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.2714285714285714,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.1,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.5285714285714286,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 138,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.6285714285714286,
                        "precision": 0.6304347826086957,
                        "recall": 0.9886363636363636,
                        "f1": 0.7699115044247787,
                        "true_negative_rate": 0.007142857142857143,
                        "false_positive_rate": 0.36428571428571427,
                        "false_negative_rate": 0.007142857142857143,
                        "true_positive_rate": 0.6214285714285714
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6285714285714286,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6304347826086957,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.9886363636363636,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7699115044247787,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.007142857142857143,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.36428571428571427,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.007142857142857143,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.6214285714285714,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 60,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.42857142857142855,
                        "precision": 0.6,
                        "recall": 0.4090909090909091,
                        "f1": 0.4864864864864865,
                        "true_negative_rate": 0.2,
                        "false_positive_rate": 0.17142857142857143,
                        "false_negative_rate": 0.37142857142857144,
                        "true_positive_rate": 0.2571428571428571
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.42857142857142855,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.4090909090909091,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.4864864864864865,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.2,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.17142857142857143,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.37142857142857144,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.2571428571428571,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 126,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.6571428571428571,
                        "precision": 0.6587301587301587,
                        "recall": 0.9431818181818182,
                        "f1": 0.7757009345794392,
                        "true_negative_rate": 0.06428571428571428,
                        "false_positive_rate": 0.30714285714285716,
                        "false_negative_rate": 0.03571428571428571,
                        "true_positive_rate": 0.5928571428571429
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6571428571428571,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6587301587301587,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.9431818181818182,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7757009345794392,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.06428571428571428,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.30714285714285716,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.03571428571428571,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.5928571428571429,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 89,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.5642857142857143,
                        "precision": 0.651685393258427,
                        "recall": 0.6590909090909091,
                        "f1": 0.655367231638418,
                        "true_negative_rate": 0.15,
                        "false_positive_rate": 0.22142857142857142,
                        "false_negative_rate": 0.21428571428571427,
                        "true_positive_rate": 0.4142857142857143
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5642857142857143,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.651685393258427,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.6590909090909091,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.655367231638418,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.15,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.22142857142857142,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.21428571428571427,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.4142857142857143,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 66,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.5857142857142857,
                        "precision": 0.7272727272727273,
                        "recall": 0.5454545454545454,
                        "f1": 0.6233766233766234,
                        "true_negative_rate": 0.24285714285714285,
                        "false_positive_rate": 0.12857142857142856,
                        "false_negative_rate": 0.2857142857142857,
                        "true_positive_rate": 0.34285714285714286
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5857142857142857,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7272727272727273,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5454545454545454,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.6233766233766234,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.24285714285714285,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.12857142857142856,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.2857142857142857,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.34285714285714286,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-3.5-turbo-0125": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 63,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.5642857142857143,
                        "precision": 0.7142857142857143,
                        "recall": 0.5113636363636364,
                        "f1": 0.5960264900662252,
                        "true_negative_rate": 0.24285714285714285,
                        "false_positive_rate": 0.12857142857142856,
                        "false_negative_rate": 0.30714285714285716,
                        "true_positive_rate": 0.32142857142857145
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5642857142857143,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7142857142857143,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5113636363636364,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.5960264900662252,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.24285714285714285,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.12857142857142856,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.30714285714285716,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.32142857142857145,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=models/gemini-1.0-pro-001": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 47,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.4785714285714286,
                        "precision": 0.6595744680851063,
                        "recall": 0.3522727272727273,
                        "f1": 0.45925925925925926,
                        "true_negative_rate": 0.2571428571428571,
                        "false_positive_rate": 0.11428571428571428,
                        "false_negative_rate": 0.40714285714285714,
                        "true_positive_rate": 0.22142857142857142
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4785714285714286,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6595744680851063,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.3522727272727273,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.45925925925925926,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.2571428571428571,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.11428571428571428,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.40714285714285714,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.22142857142857142,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=claude-3-opus-20240229": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 28,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.44285714285714284,
                        "precision": 0.6785714285714286,
                        "recall": 0.2159090909090909,
                        "f1": 0.3275862068965517,
                        "true_negative_rate": 0.30714285714285716,
                        "false_positive_rate": 0.06428571428571428,
                        "false_negative_rate": 0.4928571428571429,
                        "true_positive_rate": 0.1357142857142857
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.44285714285714284,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6785714285714286,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.2159090909090909,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.3275862068965517,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.30714285714285716,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.06428571428571428,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4928571428571429,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.1357142857142857,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0613": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 6,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.4142857142857143,
                        "precision": 1.0,
                        "recall": 0.06818181818181818,
                        "f1": 0.1276595744680851,
                        "true_negative_rate": 0.37142857142857144,
                        "false_positive_rate": 0.0,
                        "false_negative_rate": 0.5857142857142857,
                        "true_positive_rate": 0.04285714285714286
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4142857142857143,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.06818181818181818,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.1276595744680851,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.37142857142857144,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.5857142857142857,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.04285714285714286,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0125-preview": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 17,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": 0.4785714285714286,
                        "precision": 0.9411764705882353,
                        "recall": 0.18181818181818182,
                        "f1": 0.3047619047619048,
                        "true_negative_rate": 0.36428571428571427,
                        "false_positive_rate": 0.007142857142857143,
                        "false_negative_rate": 0.5142857142857142,
                        "true_positive_rate": 0.11428571428571428
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 88,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4785714285714286,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9411764705882353,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.18181818181818182,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.3047619047619048,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.36428571428571427,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.007142857142857143,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.5142857142857142,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.11428571428571428,
                            "stdev": 0.0
                        }
                    }
                }
            }
        },
        "initial_model=meta-llama/Llama-2-70b-chat-hf": {
            "baseline_model=google/gemma-7b-it": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 137,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.7125,
                        "precision": 0.8029197080291971,
                        "recall": 0.8527131782945736,
                        "f1": 0.8270676691729323,
                        "true_negative_rate": 0.025,
                        "false_positive_rate": 0.16875,
                        "false_negative_rate": 0.11875,
                        "true_positive_rate": 0.6875
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.7125,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8029197080291971,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.8527131782945736,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.8270676691729323,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.025,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.16875,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.11875,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.6875,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 126,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.7625,
                        "precision": 0.8650793650793651,
                        "recall": 0.8449612403100775,
                        "f1": 0.8549019607843137,
                        "true_negative_rate": 0.0875,
                        "false_positive_rate": 0.10625,
                        "false_negative_rate": 0.125,
                        "true_positive_rate": 0.68125
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.7625,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8650793650793651,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.8449612403100775,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.8549019607843137,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.0875,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.10625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.68125,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 159,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.8,
                        "precision": 0.8050314465408805,
                        "recall": 0.9922480620155039,
                        "f1": 0.8888888888888888,
                        "true_negative_rate": 0.0,
                        "false_positive_rate": 0.19375,
                        "false_negative_rate": 0.00625,
                        "true_positive_rate": 0.8
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.8,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8050314465408805,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.9922480620155039,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.8888888888888888,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.19375,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.00625,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.8,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 54,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.48125,
                        "precision": 0.9259259259259259,
                        "recall": 0.3875968992248062,
                        "f1": 0.546448087431694,
                        "true_negative_rate": 0.16875,
                        "false_positive_rate": 0.025,
                        "false_negative_rate": 0.49375,
                        "true_positive_rate": 0.3125
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.48125,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9259259259259259,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.3875968992248062,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.546448087431694,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.16875,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.025,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.49375,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.3125,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 83,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.625,
                        "precision": 0.9156626506024096,
                        "recall": 0.5891472868217055,
                        "f1": 0.7169811320754716,
                        "true_negative_rate": 0.15,
                        "false_positive_rate": 0.04375,
                        "false_negative_rate": 0.33125,
                        "true_positive_rate": 0.475
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.625,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9156626506024096,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5891472868217055,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7169811320754716,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.15,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.04375,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.33125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.475,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 42,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.3,
                        "precision": 0.7142857142857143,
                        "recall": 0.23255813953488372,
                        "f1": 0.3508771929824561,
                        "true_negative_rate": 0.11875,
                        "false_positive_rate": 0.075,
                        "false_negative_rate": 0.61875,
                        "true_positive_rate": 0.1875
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.3,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7142857142857143,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.23255813953488372,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.3508771929824561,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.11875,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.075,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.61875,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.1875,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 49,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.475,
                        "precision": 0.9591836734693877,
                        "recall": 0.3643410852713178,
                        "f1": 0.5280898876404494,
                        "true_negative_rate": 0.18125,
                        "false_positive_rate": 0.0125,
                        "false_negative_rate": 0.5125,
                        "true_positive_rate": 0.29375
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.475,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9591836734693877,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.3643410852713178,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.5280898876404494,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.18125,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0125,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.5125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.29375,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-3.5-turbo-0125": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 28,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.36875,
                        "precision": 1.0,
                        "recall": 0.21705426356589147,
                        "f1": 0.35668789808917195,
                        "true_negative_rate": 0.19375,
                        "false_positive_rate": 0.0,
                        "false_negative_rate": 0.63125,
                        "true_positive_rate": 0.175
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.36875,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.21705426356589147,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.35668789808917195,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.19375,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.63125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.175,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=models/gemini-1.0-pro-001": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 48,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.44375,
                        "precision": 0.9166666666666666,
                        "recall": 0.34108527131782945,
                        "f1": 0.4971751412429379,
                        "true_negative_rate": 0.16875,
                        "false_positive_rate": 0.025,
                        "false_negative_rate": 0.53125,
                        "true_positive_rate": 0.275
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.44375,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9166666666666666,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.34108527131782945,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.4971751412429379,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.16875,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.025,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.53125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.275,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=claude-3-opus-20240229": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 64,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.59375,
                        "precision": 1.0,
                        "recall": 0.49612403100775193,
                        "f1": 0.6632124352331606,
                        "true_negative_rate": 0.19375,
                        "false_positive_rate": 0.0,
                        "false_negative_rate": 0.40625,
                        "true_positive_rate": 0.4
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.59375,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.49612403100775193,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.6632124352331606,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.19375,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.40625,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.4,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0613": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 35,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.375,
                        "precision": 0.9142857142857143,
                        "recall": 0.24806201550387597,
                        "f1": 0.3902439024390244,
                        "true_negative_rate": 0.175,
                        "false_positive_rate": 0.01875,
                        "false_negative_rate": 0.60625,
                        "true_positive_rate": 0.2
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.375,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9142857142857143,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.24806201550387597,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.3902439024390244,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.175,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.01875,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.60625,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.2,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0125-preview": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 74,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": 0.55625,
                        "precision": 0.8918918918918919,
                        "recall": 0.5116279069767442,
                        "f1": 0.6502463054187192,
                        "true_negative_rate": 0.14375,
                        "false_positive_rate": 0.05,
                        "false_negative_rate": 0.39375,
                        "true_positive_rate": 0.4125
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 129,
                    "metrics": {
                        "accuracy": {
                            "average": 0.55625,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8918918918918919,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5116279069767442,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.6502463054187192,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.14375,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.05,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.39375,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.4125,
                            "stdev": 0.0
                        }
                    }
                }
            }
        }
    },
    "answerability_classification": {
        "initial_model=gpt-4-0613": {
            "baseline_model=google/gemma-7b-it": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 114,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.55,
                        "precision": 0.6052631578947368,
                        "recall": 0.7931034482758621,
                        "f1": 0.6865671641791045,
                        "true_negative_rate": 0.05714285714285714,
                        "false_positive_rate": 0.32142857142857145,
                        "false_negative_rate": 0.12857142857142856,
                        "true_positive_rate": 0.4928571428571429
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.55,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6052631578947368,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.7931034482758621,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.6865671641791045,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.05714285714285714,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.32142857142857145,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.12857142857142856,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.4928571428571429,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 120,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.6214285714285714,
                        "precision": 0.6416666666666667,
                        "recall": 0.8850574712643678,
                        "f1": 0.7439613526570048,
                        "true_negative_rate": 0.07142857142857142,
                        "false_positive_rate": 0.30714285714285716,
                        "false_negative_rate": 0.07142857142857142,
                        "true_positive_rate": 0.55
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6214285714285714,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6416666666666667,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.8850574712643678,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7439613526570048,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.07142857142857142,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.30714285714285716,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.07142857142857142,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.55,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.6214285714285714,
                        "precision": 0.6214285714285714,
                        "recall": 1.0,
                        "f1": 0.7665198237885462,
                        "true_negative_rate": 0.0,
                        "false_positive_rate": 0.37857142857142856,
                        "false_negative_rate": 0.0,
                        "true_positive_rate": 0.6214285714285714
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6214285714285714,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6214285714285714,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7665198237885462,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.37857142857142856,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.6214285714285714,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 106,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.55,
                        "precision": 0.6132075471698113,
                        "recall": 0.7471264367816092,
                        "f1": 0.6735751295336787,
                        "true_negative_rate": 0.08571428571428572,
                        "false_positive_rate": 0.29285714285714287,
                        "false_negative_rate": 0.15714285714285714,
                        "true_positive_rate": 0.4642857142857143
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.55,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6132075471698113,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.7471264367816092,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.6735751295336787,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.08571428571428572,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.29285714285714287,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.15714285714285714,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.4642857142857143,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 44,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.4857142857142857,
                        "precision": 0.7045454545454546,
                        "recall": 0.3563218390804598,
                        "f1": 0.4732824427480916,
                        "true_negative_rate": 0.2857142857142857,
                        "false_positive_rate": 0.09285714285714286,
                        "false_negative_rate": 0.4,
                        "true_positive_rate": 0.22142857142857142
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4857142857142857,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7045454545454546,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.3563218390804598,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.4732824427480916,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.2857142857142857,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.09285714285714286,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.22142857142857142,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 94,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.5428571428571428,
                        "precision": 0.6276595744680851,
                        "recall": 0.6781609195402298,
                        "f1": 0.6519337016574586,
                        "true_negative_rate": 0.12857142857142856,
                        "false_positive_rate": 0.25,
                        "false_negative_rate": 0.2,
                        "true_positive_rate": 0.42142857142857143
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5428571428571428,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6276595744680851,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.6781609195402298,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.6519337016574586,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.12857142857142856,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.25,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.2,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.42142857142857143,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 20,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.4357142857142857,
                        "precision": 0.7,
                        "recall": 0.16091954022988506,
                        "f1": 0.2616822429906542,
                        "true_negative_rate": 0.3357142857142857,
                        "false_positive_rate": 0.04285714285714286,
                        "false_negative_rate": 0.5214285714285715,
                        "true_positive_rate": 0.1
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4357142857142857,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.16091954022988506,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.2616822429906542,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.3357142857142857,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.04285714285714286,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.5214285714285715,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.1,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-3.5-turbo-0125": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 23,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.44285714285714284,
                        "precision": 0.6956521739130435,
                        "recall": 0.1839080459770115,
                        "f1": 0.2909090909090909,
                        "true_negative_rate": 0.32857142857142857,
                        "false_positive_rate": 0.05,
                        "false_negative_rate": 0.5071428571428571,
                        "true_positive_rate": 0.11428571428571428
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.44285714285714284,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6956521739130435,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.1839080459770115,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.2909090909090909,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.32857142857142857,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.05,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.5071428571428571,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.11428571428571428,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=models/gemini-1.0-pro-001": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 31,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.44285714285714284,
                        "precision": 0.6451612903225806,
                        "recall": 0.22988505747126436,
                        "f1": 0.3389830508474576,
                        "true_negative_rate": 0.3,
                        "false_positive_rate": 0.07857142857142857,
                        "false_negative_rate": 0.4785714285714286,
                        "true_positive_rate": 0.14285714285714285
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.44285714285714284,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.6451612903225806,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.22988505747126436,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.3389830508474576,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.3,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.07857142857142857,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4785714285714286,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.14285714285714285,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=claude-3-opus-20240229": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 30,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.4642857142857143,
                        "precision": 0.7,
                        "recall": 0.2413793103448276,
                        "f1": 0.358974358974359,
                        "true_negative_rate": 0.3142857142857143,
                        "false_positive_rate": 0.06428571428571428,
                        "false_negative_rate": 0.4714285714285714,
                        "true_positive_rate": 0.15
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4642857142857143,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.2413793103448276,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.358974358974359,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.3142857142857143,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.06428571428571428,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4714285714285714,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.15,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0613": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 12,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.42142857142857143,
                        "precision": 0.75,
                        "recall": 0.10344827586206896,
                        "f1": 0.18181818181818182,
                        "true_negative_rate": 0.35714285714285715,
                        "false_positive_rate": 0.02142857142857143,
                        "false_negative_rate": 0.5571428571428572,
                        "true_positive_rate": 0.06428571428571428
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.42142857142857143,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.75,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.10344827586206896,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.18181818181818182,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.35714285714285715,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.02142857142857143,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.5571428571428572,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.06428571428571428,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0125-preview": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 140,
                    "prediction_error_num": 20,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": 0.4642857142857143,
                        "precision": 0.8,
                        "recall": 0.1839080459770115,
                        "f1": 0.29906542056074764,
                        "true_negative_rate": 0.35,
                        "false_positive_rate": 0.02857142857142857,
                        "false_negative_rate": 0.5071428571428571,
                        "true_positive_rate": 0.11428571428571428
                    }
                },
                "average": {
                    "total_num": 140,
                    "gold_error_num": 87,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4642857142857143,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.1839080459770115,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.29906542056074764,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.35,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.02857142857142857,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.5071428571428571,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.11428571428571428,
                            "stdev": 0.0
                        }
                    }
                }
            }
        },
        "initial_model=meta-llama/Llama-2-70b-chat-hf": {
            "baseline_model=google/gemma-7b-it": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 57,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.38125,
                        "precision": 0.7719298245614035,
                        "recall": 0.3384615384615385,
                        "f1": 0.47058823529411764,
                        "true_negative_rate": 0.10625,
                        "false_positive_rate": 0.08125,
                        "false_negative_rate": 0.5375,
                        "true_positive_rate": 0.275
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.38125,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7719298245614035,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.3384615384615385,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.47058823529411764,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.10625,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.08125,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.5375,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.275,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 120,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.6625,
                        "precision": 0.8166666666666667,
                        "recall": 0.7538461538461538,
                        "f1": 0.784,
                        "true_negative_rate": 0.05,
                        "false_positive_rate": 0.1375,
                        "false_negative_rate": 0.2,
                        "true_positive_rate": 0.6125
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6625,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8166666666666667,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.7538461538461538,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.784,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.05,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.1375,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.2,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.6125,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 157,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.80625,
                        "precision": 0.8152866242038217,
                        "recall": 0.9846153846153847,
                        "f1": 0.89198606271777,
                        "true_negative_rate": 0.00625,
                        "false_positive_rate": 0.18125,
                        "false_negative_rate": 0.0125,
                        "true_positive_rate": 0.8
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.80625,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8152866242038217,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.9846153846153847,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.89198606271777,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.00625,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.18125,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.0125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.8,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 74,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.475,
                        "precision": 0.8108108108108109,
                        "recall": 0.46153846153846156,
                        "f1": 0.5882352941176471,
                        "true_negative_rate": 0.1,
                        "false_positive_rate": 0.0875,
                        "false_negative_rate": 0.4375,
                        "true_positive_rate": 0.375
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.475,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8108108108108109,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.46153846153846156,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.5882352941176471,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.1,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0875,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4375,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.375,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 17,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.225,
                        "precision": 0.7647058823529411,
                        "recall": 0.1,
                        "f1": 0.17687074829931973,
                        "true_negative_rate": 0.1625,
                        "false_positive_rate": 0.025,
                        "false_negative_rate": 0.73125,
                        "true_positive_rate": 0.08125
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.225,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.7647058823529411,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.1,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.17687074829931973,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.1625,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.025,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.73125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.08125,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 48,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.36875,
                        "precision": 0.8125,
                        "recall": 0.3,
                        "f1": 0.43820224719101125,
                        "true_negative_rate": 0.13125,
                        "false_positive_rate": 0.05625,
                        "false_negative_rate": 0.56875,
                        "true_positive_rate": 0.24375
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.36875,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8125,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.3,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.43820224719101125,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.13125,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.05625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.56875,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.24375,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 18,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.2875,
                        "precision": 0.9444444444444444,
                        "recall": 0.13076923076923078,
                        "f1": 0.22972972972972974,
                        "true_negative_rate": 0.18125,
                        "false_positive_rate": 0.00625,
                        "false_negative_rate": 0.70625,
                        "true_positive_rate": 0.10625
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.2875,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9444444444444444,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.13076923076923078,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.22972972972972974,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.18125,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.00625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.70625,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.10625,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-3.5-turbo-0125": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 4,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.2,
                        "precision": 0.75,
                        "recall": 0.023076923076923078,
                        "f1": 0.04477611940298507,
                        "true_negative_rate": 0.18125,
                        "false_positive_rate": 0.00625,
                        "false_negative_rate": 0.79375,
                        "true_positive_rate": 0.01875
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.2,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.75,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.023076923076923078,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.04477611940298507,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.18125,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.00625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.79375,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.01875,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=models/gemini-1.0-pro-001": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 12,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.2375,
                        "precision": 0.8333333333333334,
                        "recall": 0.07692307692307693,
                        "f1": 0.14084507042253522,
                        "true_negative_rate": 0.175,
                        "false_positive_rate": 0.0125,
                        "false_negative_rate": 0.75,
                        "true_positive_rate": 0.0625
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.2375,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.8333333333333334,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.07692307692307693,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.14084507042253522,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.175,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0125,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.75,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.0625,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=claude-3-opus-20240229": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 16,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.2875,
                        "precision": 1.0,
                        "recall": 0.12307692307692308,
                        "f1": 0.2191780821917808,
                        "true_negative_rate": 0.1875,
                        "false_positive_rate": 0.0,
                        "false_negative_rate": 0.7125,
                        "true_positive_rate": 0.1
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.2875,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.12307692307692308,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.2191780821917808,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.1875,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.7125,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.1,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0613": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 55,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.51875,
                        "precision": 0.9818181818181818,
                        "recall": 0.4153846153846154,
                        "f1": 0.5837837837837838,
                        "true_negative_rate": 0.18125,
                        "false_positive_rate": 0.00625,
                        "false_negative_rate": 0.475,
                        "true_positive_rate": 0.3375
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.51875,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9818181818181818,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.4153846153846154,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.5837837837837838,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.18125,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.00625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.475,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.3375,
                            "stdev": 0.0
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0125-preview": {
                "prompt=cot_instruction_prompt": {
                    "total_num": 160,
                    "prediction_error_num": 83,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": 0.69375,
                        "precision": 0.9879518072289156,
                        "recall": 0.6307692307692307,
                        "f1": 0.7699530516431925,
                        "true_negative_rate": 0.18125,
                        "false_positive_rate": 0.00625,
                        "false_negative_rate": 0.3,
                        "true_positive_rate": 0.5125
                    }
                },
                "average": {
                    "total_num": 160,
                    "gold_error_num": 130,
                    "metrics": {
                        "accuracy": {
                            "average": 0.69375,
                            "stdev": 0.0
                        },
                        "precision": {
                            "average": 0.9879518072289156,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.6307692307692307,
                            "stdev": 0.0
                        },
                        "f1": {
                            "average": 0.7699530516431925,
                            "stdev": 0.0
                        },
                        "true_negative_rate": {
                            "average": 0.18125,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.00625,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.3,
                            "stdev": 0.0
                        },
                        "true_positive_rate": {
                            "average": 0.5125,
                            "stdev": 0.0
                        }
                    }
                }
            }
        }
    },
    "average": {
        "initial_model=gpt-4-0613": {
            "baseline_model=google/gemma-7b-it": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.55,
                            "stdev": 0.05248906591678241
                        },
                        "precision": {
                            "average": 0.6243320976051239,
                            "stdev": 0.013511215204900033
                        },
                        "recall": {
                            "average": 0.7244427028909787,
                            "stdev": 0.19423913027786327
                        },
                        "f1": {
                            "average": 0.6566334991708126,
                            "stdev": 0.09095101002456428
                        },
                        "true_negative_rate": {
                            "average": 0.10238095238095239,
                            "stdev": 0.07961073093952613
                        },
                        "false_positive_rate": {
                            "average": 0.2738095238095238,
                            "stdev": 0.07766431633476233
                        },
                        "false_negative_rate": {
                            "average": 0.1714285714285714,
                            "stdev": 0.12051476890327394
                        },
                        "true_positive_rate": {
                            "average": 0.4523809523809524,
                            "stdev": 0.12293648231833894
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5190476190476191,
                            "stdev": 0.1498676664938687
                        },
                        "precision": {
                            "average": 0.5790545203588682,
                            "stdev": 0.1023115872195159
                        },
                        "recall": {
                            "average": 0.6519505398815744,
                            "stdev": 0.29898910064157225
                        },
                        "f1": {
                            "average": 0.5949044107854177,
                            "stdev": 0.2080035364074663
                        },
                        "true_negative_rate": {
                            "average": 0.12142857142857144,
                            "stdev": 0.051837002516850576
                        },
                        "false_positive_rate": {
                            "average": 0.25476190476190474,
                            "stdev": 0.05095460609293499
                        },
                        "false_negative_rate": {
                            "average": 0.21666666666666667,
                            "stdev": 0.18556159779427348
                        },
                        "true_positive_rate": {
                            "average": 0.4071428571428572,
                            "stdev": 0.18708286933869708
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.6238095238095238,
                            "stdev": 0.003367175148507357
                        },
                        "precision": {
                            "average": 0.6250172532781229,
                            "stdev": 0.0038975609712466304
                        },
                        "recall": {
                            "average": 0.9923807035876001,
                            "stdev": 0.005387920039815817
                        },
                        "f1": {
                            "average": 0.7669585908859231,
                            "stdev": 0.0022533787418672025
                        },
                        "true_negative_rate": {
                            "average": 0.0047619047619047615,
                            "stdev": 0.003367175148507369
                        },
                        "false_positive_rate": {
                            "average": 0.37142857142857144,
                            "stdev": 0.005832118435198045
                        },
                        "false_negative_rate": {
                            "average": 0.0047619047619047615,
                            "stdev": 0.003367175148507369
                        },
                        "true_positive_rate": {
                            "average": 0.6190476190476191,
                            "stdev": 0.003367175148507357
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4714285714285715,
                            "stdev": 0.0556348640264187
                        },
                        "precision": {
                            "average": 0.6155136268343816,
                            "stdev": 0.013705626103715849
                        },
                        "recall": {
                            "average": 0.45820271682340646,
                            "stdev": 0.21863107346897506
                        },
                        "f1": {
                            "average": 0.4949493136021634,
                            "stdev": 0.14251812086272705
                        },
                        "true_negative_rate": {
                            "average": 0.19523809523809524,
                            "stdev": 0.08754655386119159
                        },
                        "false_positive_rate": {
                            "average": 0.18095238095238098,
                            "stdev": 0.08774059891756324
                        },
                        "false_negative_rate": {
                            "average": 0.33809523809523806,
                            "stdev": 0.13619380615309612
                        },
                        "true_positive_rate": {
                            "average": 0.2857142857142857,
                            "stdev": 0.13565161460232492
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5714285714285715,
                            "stdev": 0.06998542122237651
                        },
                        "precision": {
                            "average": 0.6903226403226403,
                            "stdev": 0.022376167992761594
                        },
                        "recall": {
                            "average": 0.609413096482062,
                            "stdev": 0.2462827625608373
                        },
                        "f1": {
                            "average": 0.6180821784074225,
                            "stdev": 0.12379413425943682
                        },
                        "true_negative_rate": {
                            "average": 0.1976190476190476,
                            "stdev": 0.09589062174096319
                        },
                        "false_positive_rate": {
                            "average": 0.17857142857142858,
                            "stdev": 0.09258200997725516
                        },
                        "false_negative_rate": {
                            "average": 0.24285714285714288,
                            "stdev": 0.152863818278805
                        },
                        "true_positive_rate": {
                            "average": 0.38095238095238093,
                            "stdev": 0.1560931752674644
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5785714285714286,
                            "stdev": 0.03642156795423419
                        },
                        "precision": {
                            "average": 0.6630074623604503,
                            "stdev": 0.03442744696246624
                        },
                        "recall": {
                            "average": 0.6986241727621038,
                            "stdev": 0.04313237650234065
                        },
                        "f1": {
                            "average": 0.6802114222097365,
                            "stdev": 0.03758900870467335
                        },
                        "true_negative_rate": {
                            "average": 0.15476190476190477,
                            "stdev": 0.023570226039551594
                        },
                        "false_positive_rate": {
                            "average": 0.22142857142857142,
                            "stdev": 0.02332847374079217
                        },
                        "false_negative_rate": {
                            "average": 0.1880952380952381,
                            "stdev": 0.027561516435214824
                        },
                        "true_positive_rate": {
                            "average": 0.4357142857142857,
                            "stdev": 0.025421614885788823
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5595238095238095,
                            "stdev": 0.09227534464321953
                        },
                        "precision": {
                            "average": 0.7104514533085963,
                            "stdev": 0.012010589067177373
                        },
                        "recall": {
                            "average": 0.4998258446534309,
                            "stdev": 0.26009691418221953
                        },
                        "f1": {
                            "average": 0.5436682707710746,
                            "stdev": 0.2055770733104102
                        },
                        "true_negative_rate": {
                            "average": 0.25,
                            "stdev": 0.06725927091345492
                        },
                        "false_positive_rate": {
                            "average": 0.12619047619047621,
                            "stdev": 0.06709048954097796
                        },
                        "false_negative_rate": {
                            "average": 0.3119047619047619,
                            "stdev": 0.16144893817299702
                        },
                        "true_positive_rate": {
                            "average": 0.3119047619047619,
                            "stdev": 0.16186974411222416
                        }
                    }
                }
            },
            "baseline_model=gpt-3.5-turbo-0125": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5761904761904761,
                            "stdev": 0.11403742871264808
                        },
                        "precision": {
                            "average": 0.713569039655996,
                            "stdev": 0.014345432198760076
                        },
                        "recall": {
                            "average": 0.5229449669104842,
                            "stdev": 0.2816696168944522
                        },
                        "f1": {
                            "average": 0.5609156997666411,
                            "stdev": 0.20761533501344295
                        },
                        "true_negative_rate": {
                            "average": 0.25,
                            "stdev": 0.061445180478875906
                        },
                        "false_positive_rate": {
                            "average": 0.1261904761904762,
                            "stdev": 0.06126038252508861
                        },
                        "false_negative_rate": {
                            "average": 0.2976190476190476,
                            "stdev": 0.17509310772238318
                        },
                        "true_positive_rate": {
                            "average": 0.3261904761904762,
                            "stdev": 0.17499595071440913
                        }
                    }
                }
            },
            "baseline_model=models/gemini-1.0-pro-001": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.47380952380952385,
                            "stdev": 0.023570226039551594
                        },
                        "precision": {
                            "average": 0.6825309670882765,
                            "stdev": 0.04306096867988962
                        },
                        "recall": {
                            "average": 0.29366945315221177,
                            "stdev": 0.050098692233936
                        },
                        "f1": {
                            "average": 0.4081572727678127,
                            "stdev": 0.05073818974256117
                        },
                        "true_negative_rate": {
                            "average": 0.2904761904761905,
                            "stdev": 0.024281045302822792
                        },
                        "false_positive_rate": {
                            "average": 0.0857142857142857,
                            "stdev": 0.02102800206268535
                        },
                        "false_negative_rate": {
                            "average": 0.44047619047619047,
                            "stdev": 0.029354352395090374
                        },
                        "true_positive_rate": {
                            "average": 0.18333333333333335,
                            "stdev": 0.032120803721981055
                        }
                    }
                }
            },
            "baseline_model=claude-3-opus-20240229": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.530952380952381,
                            "stdev": 0.10978230365141434
                        },
                        "precision": {
                            "average": 0.7436768149882903,
                            "stdev": 0.07741649878107668
                        },
                        "recall": {
                            "average": 0.3516631835597353,
                            "stdev": 0.17428557696105182
                        },
                        "f1": {
                            "average": 0.4630877561912045,
                            "stdev": 0.16991722684196564
                        },
                        "true_negative_rate": {
                            "average": 0.3119047619047619,
                            "stdev": 0.003367175148507357
                        },
                        "false_positive_rate": {
                            "average": 0.06428571428571428,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4047619047619048,
                            "stdev": 0.10978230365141434
                        },
                        "true_positive_rate": {
                            "average": 0.21904761904761905,
                            "stdev": 0.1079073256535682
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0613": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5238095238095238,
                            "stdev": 0.14986766649386873
                        },
                        "precision": {
                            "average": 0.8988095238095237,
                            "stdev": 0.10747303622183206
                        },
                        "recall": {
                            "average": 0.2602751654475792,
                            "stdev": 0.24714358784936974
                        },
                        "f1": {
                            "average": 0.3502454991816694,
                            "stdev": 0.2773707570470045
                        },
                        "true_negative_rate": {
                            "average": 0.36190476190476195,
                            "stdev": 0.00673435029701474
                        },
                        "false_positive_rate": {
                            "average": 0.014285714285714285,
                            "stdev": 0.010101525445522107
                        },
                        "false_negative_rate": {
                            "average": 0.4619047619047619,
                            "stdev": 0.15532863266952465
                        },
                        "true_positive_rate": {
                            "average": 0.1619047619047619,
                            "stdev": 0.15345602899354302
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0125-preview": {
                "average": {
                    "total_num": 420,
                    "gold_error_num": 262,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5499999999999999,
                            "stdev": 0.11126972805283737
                        },
                        "precision": {
                            "average": 0.8792427315753888,
                            "stdev": 0.05892028445046363
                        },
                        "recall": {
                            "average": 0.32114245907349354,
                            "stdev": 0.19555838649002866
                        },
                        "f1": {
                            "average": 0.44035623487766573,
                            "stdev": 0.1958011744750146
                        },
                        "true_negative_rate": {
                            "average": 0.3499999999999999,
                            "stdev": 0.01166423687039609
                        },
                        "false_positive_rate": {
                            "average": 0.02619047619047619,
                            "stdev": 0.014677176197545183
                        },
                        "false_negative_rate": {
                            "average": 0.4238095238095238,
                            "stdev": 0.1229364823183389
                        },
                        "true_positive_rate": {
                            "average": 0.19999999999999998,
                            "stdev": 0.1212183053462653
                        }
                    }
                }
            }
        },
        "initial_model=meta-llama/Llama-2-70b-chat-hf": {
            "baseline_model=google/gemma-7b-it": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5166666666666666,
                            "stdev": 0.1418197702093126
                        },
                        "precision": {
                            "average": 0.7730118597007429,
                            "stdev": 0.023990120867378877
                        },
                        "recall": {
                            "average": 0.5637249055853707,
                            "stdev": 0.21472359746371572
                        },
                        "f1": {
                            "average": 0.6319289151961818,
                            "stdev": 0.14748136391424407
                        },
                        "true_negative_rate": {
                            "average": 0.06458333333333333,
                            "stdev": 0.03320286968856089
                        },
                        "false_positive_rate": {
                            "average": 0.12916666666666668,
                            "stdev": 0.03620447332704743
                        },
                        "false_negative_rate": {
                            "average": 0.3520833333333333,
                            "stdev": 0.17427926981970315
                        },
                        "true_positive_rate": {
                            "average": 0.4541666666666666,
                            "stdev": 0.17270318146718922
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5958333333333333,
                            "stdev": 0.1699673171197595
                        },
                        "precision": {
                            "average": 0.8121543376260357,
                            "stdev": 0.04516809185446758
                        },
                        "recall": {
                            "average": 0.6371024647187438,
                            "stdev": 0.23252320288728828
                        },
                        "f1": {
                            "average": 0.6936303036868523,
                            "stdev": 0.18027626959846457
                        },
                        "true_negative_rate": {
                            "average": 0.08541666666666665,
                            "stdev": 0.028105703256733415
                        },
                        "false_positive_rate": {
                            "average": 0.10833333333333334,
                            "stdev": 0.023011168785806797
                        },
                        "false_negative_rate": {
                            "average": 0.2916666666666667,
                            "stdev": 0.1852175897574406
                        },
                        "true_positive_rate": {
                            "average": 0.5145833333333334,
                            "stdev": 0.1891822680791082
                        }
                    }
                }
            },
            "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.8125,
                            "stdev": 0.013501543121683045
                        },
                        "precision": {
                            "average": 0.8167944767406089,
                            "stdev": 0.010275518273364731
                        },
                        "recall": {
                            "average": 0.9896836488769628,
                            "stdev": 0.003583889312680977
                        },
                        "f1": {
                            "average": 0.8949298474513299,
                            "stdev": 0.006477773820423847
                        },
                        "true_negative_rate": {
                            "average": 0.014583333333333332,
                            "stdev": 0.01640418307085794
                        },
                        "false_positive_rate": {
                            "average": 0.17916666666666667,
                            "stdev": 0.012842529172852033
                        },
                        "false_negative_rate": {
                            "average": 0.008333333333333333,
                            "stdev": 0.0029462782549439484
                        },
                        "true_positive_rate": {
                            "average": 0.7979166666666666,
                            "stdev": 0.00294627825494399
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4020833333333333,
                            "stdev": 0.10756942202854655
                        },
                        "precision": {
                            "average": 0.8289122455789123,
                            "stdev": 0.07295308679199926
                        },
                        "recall": {
                            "average": 0.3142951202544226,
                            "stdev": 0.15884363634378376
                        },
                        "f1": {
                            "average": 0.43378334940533597,
                            "stdev": 0.18964885852303778
                        },
                        "true_negative_rate": {
                            "average": 0.14791666666666667,
                            "stdev": 0.03397813839645852
                        },
                        "false_positive_rate": {
                            "average": 0.04583333333333334,
                            "stdev": 0.029462782549439476
                        },
                        "false_negative_rate": {
                            "average": 0.5520833333333334,
                            "stdev": 0.12440832189028012
                        },
                        "true_positive_rate": {
                            "average": 0.25416666666666665,
                            "stdev": 0.12923385349392352
                        }
                    }
                }
            },
            "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4937500000000001,
                            "stdev": 0.19005207619667472
                        },
                        "precision": {
                            "average": 0.8576138837449735,
                            "stdev": 0.06637449883971216
                        },
                        "recall": {
                            "average": 0.4458615956072352,
                            "stdev": 0.24575599664663172
                        },
                        "f1": {
                            "average": 0.5483277006980828,
                            "stdev": 0.2630294758763813
                        },
                        "true_negative_rate": {
                            "average": 0.15,
                            "stdev": 0.010206207261596573
                        },
                        "false_positive_rate": {
                            "average": 0.043750000000000004,
                            "stdev": 0.015309310892394862
                        },
                        "false_negative_rate": {
                            "average": 0.4479166666666667,
                            "stdev": 0.20138409955990952
                        },
                        "true_positive_rate": {
                            "average": 0.35833333333333334,
                            "stdev": 0.19673992279713395
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4833333333333334,
                            "stdev": 0.21252042385510989
                        },
                        "precision": {
                            "average": 0.8067427790788447,
                            "stdev": 0.07325370832551968
                        },
                        "recall": {
                            "average": 0.46137354651162793,
                            "stdev": 0.2772756338663897
                        },
                        "f1": {
                            "average": 0.5536931467244891,
                            "stdev": 0.2278828001477221
                        },
                        "true_negative_rate": {
                            "average": 0.12291666666666667,
                            "stdev": 0.005892556509887901
                        },
                        "false_positive_rate": {
                            "average": 0.07083333333333333,
                            "stdev": 0.01062295731998497
                        },
                        "false_negative_rate": {
                            "average": 0.4354166666666666,
                            "stdev": 0.22484562605386738
                        },
                        "true_positive_rate": {
                            "average": 0.37083333333333335,
                            "stdev": 0.22069571183469386
                        }
                    }
                }
            },
            "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4958333333333333,
                            "stdev": 0.17921510973005472
                        },
                        "precision": {
                            "average": 0.9358247572533287,
                            "stdev": 0.02339920974402714
                        },
                        "recall": {
                            "average": 0.40982843868018287,
                            "stdev": 0.24851130846472477
                        },
                        "f1": {
                            "average": 0.5227214816521287,
                            "stdev": 0.23706551527916386
                        },
                        "true_negative_rate": {
                            "average": 0.16666666666666666,
                            "stdev": 0.02062394778460763
                        },
                        "false_positive_rate": {
                            "average": 0.027083333333333334,
                            "stdev": 0.025173012444988693
                        },
                        "false_negative_rate": {
                            "average": 0.4770833333333333,
                            "stdev": 0.2031223290422684
                        },
                        "true_positive_rate": {
                            "average": 0.32916666666666666,
                            "stdev": 0.19805915923166886
                        }
                    }
                }
            },
            "baseline_model=gpt-3.5-turbo-0125": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.4375,
                            "stdev": 0.22724573703372303
                        },
                        "precision": {
                            "average": 0.8783185840707964,
                            "stdev": 0.10216992055950987
                        },
                        "recall": {
                            "average": 0.3404603955476048,
                            "stdev": 0.3215881514201744
                        },
                        "f1": {
                            "average": 0.4104465120547854,
                            "stdev": 0.32276178843934644
                        },
                        "true_negative_rate": {
                            "average": 0.16458333333333333,
                            "stdev": 0.03280836614171588
                        },
                        "false_positive_rate": {
                            "average": 0.02916666666666667,
                            "stdev": 0.03691676072222781
                        },
                        "false_negative_rate": {
                            "average": 0.5333333333333333,
                            "stdev": 0.2619206569851938
                        },
                        "true_positive_rate": {
                            "average": 0.2729166666666667,
                            "stdev": 0.2570026210415416
                        }
                    }
                }
            },
            "baseline_model=models/gemini-1.0-pro-001": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.40625,
                            "stdev": 0.12531211034852138
                        },
                        "precision": {
                            "average": 0.9107142857142857,
                            "stdev": 0.06089686211596348
                        },
                        "recall": {
                            "average": 0.28256528274696874,
                            "stdev": 0.1498424202152578
                        },
                        "f1": {
                            "average": 0.4119487662073316,
                            "stdev": 0.1960536722760569
                        },
                        "true_negative_rate": {
                            "average": 0.1791666666666667,
                            "stdev": 0.01062295731998497
                        },
                        "false_positive_rate": {
                            "average": 0.014583333333333332,
                            "stdev": 0.007795119555779046
                        },
                        "false_negative_rate": {
                            "average": 0.5791666666666667,
                            "stdev": 0.12461747023948484
                        },
                        "true_positive_rate": {
                            "average": 0.22708333333333333,
                            "stdev": 0.11971464915465535
                        }
                    }
                }
            },
            "baseline_model=claude-3-opus-20240229": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.5729166666666666,
                            "stdev": 0.2250192892966191
                        },
                        "precision": {
                            "average": 0.9851190476190476,
                            "stdev": 0.021044844678171033
                        },
                        "recall": {
                            "average": 0.4850461513615583,
                            "stdev": 0.2911295130989725
                        },
                        "f1": {
                            "average": 0.5913523946972027,
                            "stdev": 0.2792049702657304
                        },
                        "true_negative_rate": {
                            "average": 0.18333333333333335,
                            "stdev": 0.010622957319984964
                        },
                        "false_positive_rate": {
                            "average": 0.010416666666666666,
                            "stdev": 0.01473139127471974
                        },
                        "false_negative_rate": {
                            "average": 0.4166666666666667,
                            "stdev": 0.23740860814684503
                        },
                        "true_positive_rate": {
                            "average": 0.3895833333333334,
                            "stdev": 0.23230801511977345
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0613": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.58125,
                            "stdev": 0.19889014974771038
                        },
                        "precision": {
                            "average": 0.9562770562770563,
                            "stdev": 0.02992341066456358
                        },
                        "recall": {
                            "average": 0.4997947102961638,
                            "stdev": 0.24730978469673834
                        },
                        "f1": {
                            "average": 0.6243957833627848,
                            "stdev": 0.20973922529248507
                        },
                        "true_negative_rate": {
                            "average": 0.17916666666666667,
                            "stdev": 0.002946278254943951
                        },
                        "false_positive_rate": {
                            "average": 0.014583333333333332,
                            "stdev": 0.005892556509887896
                        },
                        "false_negative_rate": {
                            "average": 0.4041666666666666,
                            "stdev": 0.20028191935924275
                        },
                        "true_positive_rate": {
                            "average": 0.4020833333333333,
                            "stdev": 0.1967399227971339
                        }
                    }
                }
            },
            "baseline_model=gpt-4-0125-preview": {
                "average": {
                    "total_num": 480,
                    "gold_error_num": 387,
                    "metrics": {
                        "accuracy": {
                            "average": 0.7020833333333334,
                            "stdev": 0.12261615807968465
                        },
                        "precision": {
                            "average": 0.9379093322138229,
                            "stdev": 0.03931943973702159
                        },
                        "recall": {
                            "average": 0.6750698792486584,
                            "stdev": 0.1547393746836561
                        },
                        "f1": {
                            "average": 0.7759432930500884,
                            "stdev": 0.10516200515314444
                        },
                        "true_negative_rate": {
                            "average": 0.15833333333333333,
                            "stdev": 0.01640418307085794
                        },
                        "false_positive_rate": {
                            "average": 0.03541666666666667,
                            "stdev": 0.02062394778460764
                        },
                        "false_negative_rate": {
                            "average": 0.2625,
                            "stdev": 0.12531211034852138
                        },
                        "true_positive_rate": {
                            "average": 0.54375,
                            "stdev": 0.12194175522218251
                        }
                    }
                }
            }
        }
    }
}