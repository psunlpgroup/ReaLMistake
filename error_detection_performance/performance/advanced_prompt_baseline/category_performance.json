{
    "math_word_problem_generation": {
        "Reasoning Correctness": {
            "initial_model=gpt-4-0613": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 15,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.42857142857142855,
                            "precision": 1.0,
                            "recall": 0.42857142857142855,
                            "f1": 0.6,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5714285714285714,
                            "true_positive_rate": 0.42857142857142855
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.42857142857142855,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.42857142857142855,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5714285714285714,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.42857142857142855,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 8,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.22857142857142856,
                            "precision": 1.0,
                            "recall": 0.22857142857142856,
                            "f1": 0.37209302325581395,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7714285714285715,
                            "true_positive_rate": 0.22857142857142856
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.22857142857142856,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.22857142857142856,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.37209302325581395,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7714285714285715,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.22857142857142856,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 1.0,
                            "precision": 1.0,
                            "recall": 1.0,
                            "f1": 1.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 1.0
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 11,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.3142857142857143,
                            "precision": 1.0,
                            "recall": 0.3142857142857143,
                            "f1": 0.4782608695652174,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6857142857142857,
                            "true_positive_rate": 0.3142857142857143
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3142857142857143,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3142857142857143,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4782608695652174,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6857142857142857,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3142857142857143,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 25,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.7142857142857143,
                            "precision": 1.0,
                            "recall": 0.7142857142857143,
                            "f1": 0.8333333333333334,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2857142857142857,
                            "true_positive_rate": 0.7142857142857143
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7142857142857143,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7142857142857143,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8333333333333334,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2857142857142857,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7142857142857143,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 28,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.8,
                            "precision": 1.0,
                            "recall": 0.8,
                            "f1": 0.8888888888888888,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2,
                            "true_positive_rate": 0.8
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8888888888888888,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 31,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.8857142857142857,
                            "precision": 1.0,
                            "recall": 0.8857142857142857,
                            "f1": 0.9393939393939394,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.11428571428571428,
                            "true_positive_rate": 0.8857142857142857
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8857142857142857,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8857142857142857,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9393939393939394,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.11428571428571428,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8857142857142857,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 31,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.8857142857142857,
                            "precision": 1.0,
                            "recall": 0.8857142857142857,
                            "f1": 0.9393939393939394,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.11428571428571428,
                            "true_positive_rate": 0.8857142857142857
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8857142857142857,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8857142857142857,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9393939393939394,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.11428571428571428,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8857142857142857,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 10,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.2857142857142857,
                            "precision": 1.0,
                            "recall": 0.2857142857142857,
                            "f1": 0.4444444444444444,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7142857142857143,
                            "true_positive_rate": 0.2857142857142857
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.2857142857142857,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.2857142857142857,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4444444444444444,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7142857142857143,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.2857142857142857,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 18,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.5142857142857142,
                            "precision": 1.0,
                            "recall": 0.5142857142857142,
                            "f1": 0.6792452830188679,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.4857142857142857,
                            "true_positive_rate": 0.5142857142857142
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5142857142857142,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5142857142857142,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6792452830188679,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.4857142857142857,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5142857142857142,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 23,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.6571428571428571,
                            "precision": 1.0,
                            "recall": 0.6571428571428571,
                            "f1": 0.7931034482758621,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.34285714285714286,
                            "true_positive_rate": 0.6571428571428571
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6571428571428571,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6571428571428571,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7931034482758621,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.34285714285714286,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6571428571428571,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 35,
                        "prediction_error_num": 26,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": 0.7428571428571429,
                            "precision": 1.0,
                            "recall": 0.7428571428571429,
                            "f1": 0.8524590163934426,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2571428571428571,
                            "true_positive_rate": 0.7428571428571429
                        }
                    },
                    "average": {
                        "total_num": 35,
                        "gold_error_num": 35,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7428571428571429,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7428571428571429,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8524590163934426,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2571428571428571,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7428571428571429,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.6214285714285714,
                            "stdev": 0.2499319635311935
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.6214285714285714,
                            "stdev": 0.2499319635311935
                        },
                        "f1": {
                            "average": 0.7350513488303124,
                            "stdev": 0.20568486682279633
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.37857142857142856,
                            "stdev": 0.24993196353119349
                        },
                        "true_positive_rate": {
                            "average": 0.6214285714285714,
                            "stdev": 0.2499319635311935
                        }
                    }
                }
            },
            "initial_model=meta-llama/Llama-2-70b-chat-hf": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 41,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.5,
                            "precision": 1.0,
                            "recall": 0.5,
                            "f1": 0.6666666666666666,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5,
                            "true_positive_rate": 0.5
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6666666666666666,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 24,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.2926829268292683,
                            "precision": 1.0,
                            "recall": 0.2926829268292683,
                            "f1": 0.4528301886792453,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7073170731707317,
                            "true_positive_rate": 0.2926829268292683
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.2926829268292683,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.2926829268292683,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4528301886792453,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7073170731707317,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.2926829268292683,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 1.0,
                            "precision": 1.0,
                            "recall": 1.0,
                            "f1": 1.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 1.0
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 6,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.07317073170731707,
                            "precision": 1.0,
                            "recall": 0.07317073170731707,
                            "f1": 0.13636363636363635,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.926829268292683,
                            "true_positive_rate": 0.07317073170731707
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.07317073170731707,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.07317073170731707,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.13636363636363635,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.926829268292683,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.07317073170731707,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 54,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.6585365853658537,
                            "precision": 1.0,
                            "recall": 0.6585365853658537,
                            "f1": 0.7941176470588235,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.34146341463414637,
                            "true_positive_rate": 0.6585365853658537
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6585365853658537,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6585365853658537,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7941176470588235,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.34146341463414637,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6585365853658537,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 75,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.9146341463414634,
                            "precision": 1.0,
                            "recall": 0.9146341463414634,
                            "f1": 0.9554140127388535,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.08536585365853659,
                            "true_positive_rate": 0.9146341463414634
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9146341463414634,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9146341463414634,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9554140127388535,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.08536585365853659,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9146341463414634,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 66,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.8048780487804879,
                            "precision": 1.0,
                            "recall": 0.8048780487804879,
                            "f1": 0.8918918918918919,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.1951219512195122,
                            "true_positive_rate": 0.8048780487804879
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8048780487804879,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8048780487804879,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8918918918918919,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.1951219512195122,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8048780487804879,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 71,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.8658536585365854,
                            "precision": 1.0,
                            "recall": 0.8658536585365854,
                            "f1": 0.9281045751633987,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.13414634146341464,
                            "true_positive_rate": 0.8658536585365854
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8658536585365854,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8658536585365854,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9281045751633987,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.13414634146341464,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8658536585365854,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 36,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.43902439024390244,
                            "precision": 1.0,
                            "recall": 0.43902439024390244,
                            "f1": 0.6101694915254238,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5609756097560976,
                            "true_positive_rate": 0.43902439024390244
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.43902439024390244,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.43902439024390244,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6101694915254238,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5609756097560976,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.43902439024390244,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 72,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.8780487804878049,
                            "precision": 1.0,
                            "recall": 0.8780487804878049,
                            "f1": 0.935064935064935,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.12195121951219512,
                            "true_positive_rate": 0.8780487804878049
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8780487804878049,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8780487804878049,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.935064935064935,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.12195121951219512,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8780487804878049,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 75,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.9146341463414634,
                            "precision": 1.0,
                            "recall": 0.9146341463414634,
                            "f1": 0.9554140127388535,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.08536585365853659,
                            "true_positive_rate": 0.9146341463414634
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9146341463414634,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9146341463414634,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9554140127388535,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.08536585365853659,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9146341463414634,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 82,
                        "prediction_error_num": 79,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": 0.9634146341463414,
                            "precision": 1.0,
                            "recall": 0.9634146341463414,
                            "f1": 0.9813664596273292,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.036585365853658534,
                            "true_positive_rate": 0.9634146341463414
                        }
                    },
                    "average": {
                        "total_num": 82,
                        "gold_error_num": 82,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9634146341463414,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9634146341463414,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9813664596273292,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.036585365853658534,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9634146341463414,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.6920731707317075,
                            "stdev": 0.2871739760568341
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.6920731707317075,
                            "stdev": 0.2871739760568341
                        },
                        "f1": {
                            "average": 0.7756169597932548,
                            "stdev": 0.25363227533252014
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.30792682926829273,
                            "stdev": 0.28717397605683403
                        },
                        "true_positive_rate": {
                            "average": 0.6920731707317075,
                            "stdev": 0.2871739760568341
                        }
                    }
                }
            }
        },
        "Instruction-Following": {
            "initial_model=gpt-4-0613": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 39,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.4875,
                            "precision": 1.0,
                            "recall": 0.4875,
                            "f1": 0.6554621848739496,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5125,
                            "true_positive_rate": 0.4875
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.4875,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.4875,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6554621848739496,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5125,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.4875,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 18,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.225,
                            "precision": 1.0,
                            "recall": 0.225,
                            "f1": 0.3673469387755102,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.775,
                            "true_positive_rate": 0.225
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.225,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.225,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.3673469387755102,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.775,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.225,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 79,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.9875,
                            "precision": 1.0,
                            "recall": 0.9875,
                            "f1": 0.9937106918238994,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0125,
                            "true_positive_rate": 0.9875
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9875,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9875,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9937106918238994,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0125,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9875,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 17,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.2125,
                            "precision": 1.0,
                            "recall": 0.2125,
                            "f1": 0.35051546391752575,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7875,
                            "true_positive_rate": 0.2125
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.2125,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.2125,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.35051546391752575,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7875,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.2125,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 40,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.5,
                            "precision": 1.0,
                            "recall": 0.5,
                            "f1": 0.6666666666666666,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5,
                            "true_positive_rate": 0.5
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6666666666666666,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 59,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.7375,
                            "precision": 1.0,
                            "recall": 0.7375,
                            "f1": 0.8489208633093526,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2625,
                            "true_positive_rate": 0.7375
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7375,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7375,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8489208633093526,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2625,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7375,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 63,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.7875,
                            "precision": 1.0,
                            "recall": 0.7875,
                            "f1": 0.8811188811188811,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2125,
                            "true_positive_rate": 0.7875
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7875,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7875,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8811188811188811,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2125,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7875,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 69,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.8625,
                            "precision": 1.0,
                            "recall": 0.8625,
                            "f1": 0.9261744966442953,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.1375,
                            "true_positive_rate": 0.8625
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8625,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8625,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9261744966442953,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.1375,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8625,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 24,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.3,
                            "precision": 1.0,
                            "recall": 0.3,
                            "f1": 0.46153846153846156,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7,
                            "true_positive_rate": 0.3
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.46153846153846156,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 49,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.6125,
                            "precision": 1.0,
                            "recall": 0.6125,
                            "f1": 0.7596899224806202,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.3875,
                            "true_positive_rate": 0.6125
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6125,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6125,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7596899224806202,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.3875,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6125,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 51,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.6375,
                            "precision": 1.0,
                            "recall": 0.6375,
                            "f1": 0.7786259541984732,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.3625,
                            "true_positive_rate": 0.6375
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6375,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6375,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7786259541984732,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.3625,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6375,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 80,
                        "prediction_error_num": 47,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": 0.5875,
                            "precision": 1.0,
                            "recall": 0.5875,
                            "f1": 0.7401574803149606,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.4125,
                            "true_positive_rate": 0.5875
                        }
                    },
                    "average": {
                        "total_num": 80,
                        "gold_error_num": 80,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5875,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5875,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7401574803149606,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.4125,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5875,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.5781250000000001,
                            "stdev": 0.2367380870814834
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5781250000000001,
                            "stdev": 0.2367380870814834
                        },
                        "f1": {
                            "average": 0.702494000471883,
                            "stdev": 0.20339644987283248
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.42187499999999994,
                            "stdev": 0.2367380870814834
                        },
                        "true_positive_rate": {
                            "average": 0.5781250000000001,
                            "stdev": 0.2367380870814834
                        }
                    }
                }
            },
            "initial_model=meta-llama/Llama-2-70b-chat-hf": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 53,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.49074074074074076,
                            "precision": 1.0,
                            "recall": 0.49074074074074076,
                            "f1": 0.6583850931677019,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5092592592592593,
                            "true_positive_rate": 0.49074074074074076
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.49074074074074076,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.49074074074074076,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6583850931677019,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5092592592592593,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.49074074074074076,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 36,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.3333333333333333,
                            "precision": 1.0,
                            "recall": 0.3333333333333333,
                            "f1": 0.5,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6666666666666666,
                            "true_positive_rate": 0.3333333333333333
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3333333333333333,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3333333333333333,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6666666666666666,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3333333333333333,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 107,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.9907407407407407,
                            "precision": 1.0,
                            "recall": 0.9907407407407407,
                            "f1": 0.9953488372093023,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.009259259259259259,
                            "true_positive_rate": 0.9907407407407407
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9907407407407407,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9907407407407407,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9953488372093023,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.009259259259259259,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9907407407407407,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 9,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.08333333333333333,
                            "precision": 1.0,
                            "recall": 0.08333333333333333,
                            "f1": 0.15384615384615385,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.9166666666666666,
                            "true_positive_rate": 0.08333333333333333
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.08333333333333333,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.08333333333333333,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.15384615384615385,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.9166666666666666,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.08333333333333333,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 74,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.6851851851851852,
                            "precision": 1.0,
                            "recall": 0.6851851851851852,
                            "f1": 0.8131868131868132,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.3148148148148148,
                            "true_positive_rate": 0.6851851851851852
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6851851851851852,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6851851851851852,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8131868131868132,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.3148148148148148,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6851851851851852,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 91,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.8425925925925926,
                            "precision": 1.0,
                            "recall": 0.8425925925925926,
                            "f1": 0.914572864321608,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.1574074074074074,
                            "true_positive_rate": 0.8425925925925926
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8425925925925926,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8425925925925926,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.914572864321608,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.1574074074074074,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8425925925925926,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 79,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.7314814814814815,
                            "precision": 1.0,
                            "recall": 0.7314814814814815,
                            "f1": 0.8449197860962567,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.26851851851851855,
                            "true_positive_rate": 0.7314814814814815
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7314814814814815,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7314814814814815,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8449197860962567,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.26851851851851855,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7314814814814815,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 86,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.7962962962962963,
                            "precision": 1.0,
                            "recall": 0.7962962962962963,
                            "f1": 0.8865979381443299,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2037037037037037,
                            "true_positive_rate": 0.7962962962962963
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7962962962962963,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7962962962962963,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8865979381443299,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2037037037037037,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7962962962962963,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 50,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.46296296296296297,
                            "precision": 1.0,
                            "recall": 0.46296296296296297,
                            "f1": 0.6329113924050633,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5370370370370371,
                            "true_positive_rate": 0.46296296296296297
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.46296296296296297,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.46296296296296297,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6329113924050633,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5370370370370371,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.46296296296296297,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 90,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.8333333333333334,
                            "precision": 1.0,
                            "recall": 0.8333333333333334,
                            "f1": 0.9090909090909091,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.16666666666666666,
                            "true_positive_rate": 0.8333333333333334
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8333333333333334,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8333333333333334,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9090909090909091,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.16666666666666666,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8333333333333334,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 90,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.8333333333333334,
                            "precision": 1.0,
                            "recall": 0.8333333333333334,
                            "f1": 0.9090909090909091,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.16666666666666666,
                            "true_positive_rate": 0.8333333333333334
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8333333333333334,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8333333333333334,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9090909090909091,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.16666666666666666,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8333333333333334,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 108,
                        "prediction_error_num": 95,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": 0.8796296296296297,
                            "precision": 1.0,
                            "recall": 0.8796296296296297,
                            "f1": 0.9359605911330049,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.12037037037037036,
                            "true_positive_rate": 0.8796296296296297
                        }
                    },
                    "average": {
                        "total_num": 108,
                        "gold_error_num": 108,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8796296296296297,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8796296296296297,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9359605911330049,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.12037037037037036,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8796296296296297,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.6635802469135802,
                            "stdev": 0.2552694915895388
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.6635802469135802,
                            "stdev": 0.2552694915895388
                        },
                        "f1": {
                            "average": 0.7628259406410044,
                            "stdev": 0.23133150384266707
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.33641975308641975,
                            "stdev": 0.2552694915895389
                        },
                        "true_positive_rate": {
                            "average": 0.6635802469135802,
                            "stdev": 0.2552694915895388
                        }
                    }
                }
            }
        }
    },
    "finegrained_fact_verification": {
        "Reasoning Correctness": {
            "initial_model=gpt-4-0613": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 35,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.9722222222222222,
                            "precision": 1.0,
                            "recall": 0.9722222222222222,
                            "f1": 0.9859154929577465,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.027777777777777776,
                            "true_positive_rate": 0.9722222222222222
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9722222222222222,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9722222222222222,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9859154929577465,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.027777777777777776,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9722222222222222,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 34,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.9444444444444444,
                            "precision": 1.0,
                            "recall": 0.9444444444444444,
                            "f1": 0.9714285714285714,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.05555555555555555,
                            "true_positive_rate": 0.9444444444444444
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9444444444444444,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9444444444444444,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9714285714285714,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.05555555555555555,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9444444444444444,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 1.0,
                            "precision": 1.0,
                            "recall": 1.0,
                            "f1": 1.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 1.0
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 21,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.5833333333333334,
                            "precision": 1.0,
                            "recall": 0.5833333333333334,
                            "f1": 0.7368421052631579,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.4166666666666667,
                            "true_positive_rate": 0.5833333333333334
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5833333333333334,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5833333333333334,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7368421052631579,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.4166666666666667,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5833333333333334,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 1.0,
                            "precision": 1.0,
                            "recall": 1.0,
                            "f1": 1.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 1.0
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 28,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.7777777777777778,
                            "precision": 1.0,
                            "recall": 0.7777777777777778,
                            "f1": 0.875,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2222222222222222,
                            "true_positive_rate": 0.7777777777777778
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7777777777777778,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7777777777777778,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.875,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2222222222222222,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7777777777777778,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 28,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.7777777777777778,
                            "precision": 1.0,
                            "recall": 0.7777777777777778,
                            "f1": 0.875,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2222222222222222,
                            "true_positive_rate": 0.7777777777777778
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7777777777777778,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7777777777777778,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.875,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2222222222222222,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7777777777777778,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 26,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.7222222222222222,
                            "precision": 1.0,
                            "recall": 0.7222222222222222,
                            "f1": 0.8387096774193549,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2777777777777778,
                            "true_positive_rate": 0.7222222222222222
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7222222222222222,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7222222222222222,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8387096774193549,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2777777777777778,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7222222222222222,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 16,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.4444444444444444,
                            "precision": 1.0,
                            "recall": 0.4444444444444444,
                            "f1": 0.6153846153846154,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5555555555555556,
                            "true_positive_rate": 0.4444444444444444
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.4444444444444444,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.4444444444444444,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6153846153846154,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5555555555555556,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.4444444444444444,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 13,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.3611111111111111,
                            "precision": 1.0,
                            "recall": 0.3611111111111111,
                            "f1": 0.5306122448979592,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6388888888888888,
                            "true_positive_rate": 0.3611111111111111
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3611111111111111,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3611111111111111,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5306122448979592,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6388888888888888,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3611111111111111,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 3,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.08333333333333333,
                            "precision": 1.0,
                            "recall": 0.08333333333333333,
                            "f1": 0.15384615384615385,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.9166666666666666,
                            "true_positive_rate": 0.08333333333333333
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.08333333333333333,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.08333333333333333,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.15384615384615385,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.9166666666666666,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.08333333333333333,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 36,
                        "prediction_error_num": 9,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": 0.25,
                            "precision": 1.0,
                            "recall": 0.25,
                            "f1": 0.4,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.75,
                            "true_positive_rate": 0.25
                        }
                    },
                    "average": {
                        "total_num": 36,
                        "gold_error_num": 36,
                        "metrics": {
                            "accuracy": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.75,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.25,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.6597222222222222,
                            "stdev": 0.3004893556861182
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.6597222222222222,
                            "stdev": 0.3004893556861182
                        },
                        "f1": {
                            "average": 0.7485615717664632,
                            "stdev": 0.2603052914948514
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.34027777777777785,
                            "stdev": 0.3004893556861182
                        },
                        "true_positive_rate": {
                            "average": 0.6597222222222222,
                            "stdev": 0.3004893556861182
                        }
                    }
                }
            },
            "initial_model=meta-llama/Llama-2-70b-chat-hf": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 77,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.8461538461538461,
                            "precision": 1.0,
                            "recall": 0.8461538461538461,
                            "f1": 0.9166666666666666,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.15384615384615385,
                            "true_positive_rate": 0.8461538461538461
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8461538461538461,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8461538461538461,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9166666666666666,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.15384615384615385,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8461538461538461,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 77,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.8461538461538461,
                            "precision": 1.0,
                            "recall": 0.8461538461538461,
                            "f1": 0.9166666666666666,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.15384615384615385,
                            "true_positive_rate": 0.8461538461538461
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8461538461538461,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8461538461538461,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9166666666666666,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.15384615384615385,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8461538461538461,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 1.0,
                            "precision": 1.0,
                            "recall": 1.0,
                            "f1": 1.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 1.0
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 38,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.4175824175824176,
                            "precision": 1.0,
                            "recall": 0.4175824175824176,
                            "f1": 0.5891472868217055,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5824175824175825,
                            "true_positive_rate": 0.4175824175824176
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.4175824175824176,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.4175824175824176,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5891472868217055,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5824175824175825,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.4175824175824176,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 58,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.6373626373626373,
                            "precision": 1.0,
                            "recall": 0.6373626373626373,
                            "f1": 0.7785234899328859,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.3626373626373626,
                            "true_positive_rate": 0.6373626373626373
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6373626373626373,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6373626373626373,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7785234899328859,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.3626373626373626,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6373626373626373,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 21,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.23076923076923078,
                            "precision": 1.0,
                            "recall": 0.23076923076923078,
                            "f1": 0.375,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7692307692307693,
                            "true_positive_rate": 0.23076923076923078
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.23076923076923078,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.23076923076923078,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.375,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7692307692307693,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.23076923076923078,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 32,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.3516483516483517,
                            "precision": 1.0,
                            "recall": 0.3516483516483517,
                            "f1": 0.5203252032520326,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6483516483516484,
                            "true_positive_rate": 0.3516483516483517
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3516483516483517,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3516483516483517,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5203252032520326,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6483516483516484,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3516483516483517,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 20,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.21978021978021978,
                            "precision": 1.0,
                            "recall": 0.21978021978021978,
                            "f1": 0.36036036036036034,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7802197802197802,
                            "true_positive_rate": 0.21978021978021978
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.21978021978021978,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.21978021978021978,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.36036036036036034,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7802197802197802,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.21978021978021978,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 33,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.3626373626373626,
                            "precision": 1.0,
                            "recall": 0.3626373626373626,
                            "f1": 0.532258064516129,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6373626373626373,
                            "true_positive_rate": 0.3626373626373626
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3626373626373626,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3626373626373626,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.532258064516129,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6373626373626373,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3626373626373626,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 50,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.5494505494505495,
                            "precision": 1.0,
                            "recall": 0.5494505494505495,
                            "f1": 0.7092198581560284,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.45054945054945056,
                            "true_positive_rate": 0.5494505494505495
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5494505494505495,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5494505494505495,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7092198581560284,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.45054945054945056,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5494505494505495,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 21,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.23076923076923078,
                            "precision": 1.0,
                            "recall": 0.23076923076923078,
                            "f1": 0.375,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7692307692307693,
                            "true_positive_rate": 0.23076923076923078
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.23076923076923078,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.23076923076923078,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.375,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7692307692307693,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.23076923076923078,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 91,
                        "prediction_error_num": 48,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": 0.5274725274725275,
                            "precision": 1.0,
                            "recall": 0.5274725274725275,
                            "f1": 0.6906474820143885,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.4725274725274725,
                            "true_positive_rate": 0.5274725274725275
                        }
                    },
                    "average": {
                        "total_num": 91,
                        "gold_error_num": 91,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5274725274725275,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5274725274725275,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6906474820143885,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.4725274725274725,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5274725274725275,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.5183150183150182,
                            "stdev": 0.2547631556048009
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5183150183150182,
                            "stdev": 0.2547631556048009
                        },
                        "f1": {
                            "average": 0.646984589865572,
                            "stdev": 0.21521568571559208
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4816849816849817,
                            "stdev": 0.25476315560480095
                        },
                        "true_positive_rate": {
                            "average": 0.5183150183150182,
                            "stdev": 0.2547631556048009
                        }
                    }
                }
            }
        },
        "Instruction-Following": {
            "initial_model=gpt-4-0613": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 7,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.875,
                            "precision": 1.0,
                            "recall": 0.875,
                            "f1": 0.9333333333333333,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.125,
                            "true_positive_rate": 0.875
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.875,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.875,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9333333333333333,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.125,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.875,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 7,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.875,
                            "precision": 1.0,
                            "recall": 0.875,
                            "f1": 0.9333333333333333,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.125,
                            "true_positive_rate": 0.875
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.875,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.875,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9333333333333333,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.125,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.875,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 7,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.875,
                            "precision": 1.0,
                            "recall": 0.875,
                            "f1": 0.9333333333333333,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.125,
                            "true_positive_rate": 0.875
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.875,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.875,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9333333333333333,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.125,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.875,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 0,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.0,
                            "precision": 0.0,
                            "recall": 0.0,
                            "f1": 0.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 1.0,
                            "true_positive_rate": 0.0
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 1.0,
                            "precision": 1.0,
                            "recall": 1.0,
                            "f1": 1.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 1.0
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 5,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.625,
                            "precision": 1.0,
                            "recall": 0.625,
                            "f1": 0.7692307692307693,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.375,
                            "true_positive_rate": 0.625
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.625,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.625,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7692307692307693,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.375,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.625,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 2,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.25,
                            "precision": 1.0,
                            "recall": 0.25,
                            "f1": 0.4,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.75,
                            "true_positive_rate": 0.25
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.75,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.25,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 2,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.25,
                            "precision": 1.0,
                            "recall": 0.25,
                            "f1": 0.4,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.75,
                            "true_positive_rate": 0.25
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.75,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.25,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 2,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.25,
                            "precision": 1.0,
                            "recall": 0.25,
                            "f1": 0.4,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.75,
                            "true_positive_rate": 0.25
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.75,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.25,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 2,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.25,
                            "precision": 1.0,
                            "recall": 0.25,
                            "f1": 0.4,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.75,
                            "true_positive_rate": 0.25
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.75,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.25,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 1,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.125,
                            "precision": 1.0,
                            "recall": 0.125,
                            "f1": 0.2222222222222222,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.875,
                            "true_positive_rate": 0.125
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.125,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.125,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.2222222222222222,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.875,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.125,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 8,
                        "prediction_error_num": 2,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": 0.25,
                            "precision": 1.0,
                            "recall": 0.25,
                            "f1": 0.4,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.75,
                            "true_positive_rate": 0.25
                        }
                    },
                    "average": {
                        "total_num": 8,
                        "gold_error_num": 8,
                        "metrics": {
                            "accuracy": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.75,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.25,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.46875,
                            "stdev": 0.3389820853181871
                        },
                        "precision": {
                            "average": 0.9166666666666666,
                            "stdev": 0.2763853991962833
                        },
                        "recall": {
                            "average": 0.46875,
                            "stdev": 0.3389820853181871
                        },
                        "f1": {
                            "average": 0.565954415954416,
                            "stdev": 0.3176448769793121
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.53125,
                            "stdev": 0.3389820853181871
                        },
                        "true_positive_rate": {
                            "average": 0.46875,
                            "stdev": 0.3389820853181871
                        }
                    }
                }
            },
            "initial_model=meta-llama/Llama-2-70b-chat-hf": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 60,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.8450704225352113,
                            "precision": 1.0,
                            "recall": 0.8450704225352113,
                            "f1": 0.916030534351145,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.15492957746478872,
                            "true_positive_rate": 0.8450704225352113
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8450704225352113,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8450704225352113,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.916030534351145,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.15492957746478872,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8450704225352113,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 60,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.8450704225352113,
                            "precision": 1.0,
                            "recall": 0.8450704225352113,
                            "f1": 0.916030534351145,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.15492957746478872,
                            "true_positive_rate": 0.8450704225352113
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8450704225352113,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8450704225352113,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.916030534351145,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.15492957746478872,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8450704225352113,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 70,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.9859154929577465,
                            "precision": 1.0,
                            "recall": 0.9859154929577465,
                            "f1": 0.9929078014184397,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.014084507042253521,
                            "true_positive_rate": 0.9859154929577465
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9859154929577465,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9859154929577465,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9929078014184397,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.014084507042253521,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9859154929577465,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 27,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.38028169014084506,
                            "precision": 1.0,
                            "recall": 0.38028169014084506,
                            "f1": 0.5510204081632653,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6197183098591549,
                            "true_positive_rate": 0.38028169014084506
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.38028169014084506,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.38028169014084506,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5510204081632653,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6197183098591549,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.38028169014084506,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 45,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.6338028169014085,
                            "precision": 1.0,
                            "recall": 0.6338028169014085,
                            "f1": 0.7758620689655172,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.36619718309859156,
                            "true_positive_rate": 0.6338028169014085
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6338028169014085,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6338028169014085,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7758620689655172,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.36619718309859156,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6338028169014085,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 11,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.15492957746478872,
                            "precision": 1.0,
                            "recall": 0.15492957746478872,
                            "f1": 0.2682926829268293,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8450704225352113,
                            "true_positive_rate": 0.15492957746478872
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.15492957746478872,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.15492957746478872,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.2682926829268293,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8450704225352113,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.15492957746478872,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 28,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.39436619718309857,
                            "precision": 1.0,
                            "recall": 0.39436619718309857,
                            "f1": 0.5656565656565656,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6056338028169014,
                            "true_positive_rate": 0.39436619718309857
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.39436619718309857,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.39436619718309857,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5656565656565656,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6056338028169014,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.39436619718309857,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 21,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.29577464788732394,
                            "precision": 1.0,
                            "recall": 0.29577464788732394,
                            "f1": 0.45652173913043476,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.704225352112676,
                            "true_positive_rate": 0.29577464788732394
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.29577464788732394,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.29577464788732394,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.45652173913043476,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.704225352112676,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.29577464788732394,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 23,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.323943661971831,
                            "precision": 1.0,
                            "recall": 0.323943661971831,
                            "f1": 0.48936170212765956,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.676056338028169,
                            "true_positive_rate": 0.323943661971831
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.323943661971831,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.323943661971831,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.48936170212765956,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.676056338028169,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.323943661971831,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 39,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.5492957746478874,
                            "precision": 1.0,
                            "recall": 0.5492957746478874,
                            "f1": 0.7090909090909091,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.4507042253521127,
                            "true_positive_rate": 0.5492957746478874
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5492957746478874,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5492957746478874,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7090909090909091,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.4507042253521127,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5492957746478874,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 22,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.30985915492957744,
                            "precision": 1.0,
                            "recall": 0.30985915492957744,
                            "f1": 0.4731182795698925,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6901408450704225,
                            "true_positive_rate": 0.30985915492957744
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.30985915492957744,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.30985915492957744,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4731182795698925,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6901408450704225,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.30985915492957744,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 71,
                        "prediction_error_num": 38,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": 0.5352112676056338,
                            "precision": 1.0,
                            "recall": 0.5352112676056338,
                            "f1": 0.6972477064220184,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.4647887323943662,
                            "true_positive_rate": 0.5352112676056338
                        }
                    },
                    "average": {
                        "total_num": 71,
                        "gold_error_num": 71,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5352112676056338,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5352112676056338,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6972477064220184,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.4647887323943662,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5352112676056338,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.5211267605633803,
                            "stdev": 0.2489812609811787
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5211267605633803,
                            "stdev": 0.2489812609811787
                        },
                        "f1": {
                            "average": 0.6509284110144851,
                            "stdev": 0.2117038305916957
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4788732394366197,
                            "stdev": 0.24898126098117873
                        },
                        "true_positive_rate": {
                            "average": 0.5211267605633803,
                            "stdev": 0.2489812609811787
                        }
                    }
                }
            }
        },
        "Context-Faithfulness": {
            "initial_model=gpt-4-0613": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 58,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.9206349206349206,
                            "precision": 1.0,
                            "recall": 0.9206349206349206,
                            "f1": 0.9586776859504132,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.07936507936507936,
                            "true_positive_rate": 0.9206349206349206
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9206349206349206,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9206349206349206,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9586776859504132,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.07936507936507936,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9206349206349206,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 51,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.8095238095238095,
                            "precision": 1.0,
                            "recall": 0.8095238095238095,
                            "f1": 0.8947368421052632,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.19047619047619047,
                            "true_positive_rate": 0.8095238095238095
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8095238095238095,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8095238095238095,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8947368421052632,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.19047619047619047,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8095238095238095,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 1.0,
                            "precision": 1.0,
                            "recall": 1.0,
                            "f1": 1.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 1.0
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 20,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.31746031746031744,
                            "precision": 1.0,
                            "recall": 0.31746031746031744,
                            "f1": 0.4819277108433735,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6825396825396826,
                            "true_positive_rate": 0.31746031746031744
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.31746031746031744,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.31746031746031744,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4819277108433735,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6825396825396826,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.31746031746031744,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 58,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.9206349206349206,
                            "precision": 1.0,
                            "recall": 0.9206349206349206,
                            "f1": 0.9586776859504132,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.07936507936507936,
                            "true_positive_rate": 0.9206349206349206
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9206349206349206,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9206349206349206,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9586776859504132,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.07936507936507936,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9206349206349206,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 37,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.5873015873015873,
                            "precision": 1.0,
                            "recall": 0.5873015873015873,
                            "f1": 0.74,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.4126984126984127,
                            "true_positive_rate": 0.5873015873015873
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5873015873015873,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5873015873015873,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.74,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.4126984126984127,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5873015873015873,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 28,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.4444444444444444,
                            "precision": 1.0,
                            "recall": 0.4444444444444444,
                            "f1": 0.6153846153846154,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5555555555555556,
                            "true_positive_rate": 0.4444444444444444
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.4444444444444444,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.4444444444444444,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6153846153846154,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5555555555555556,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.4444444444444444,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 25,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.3968253968253968,
                            "precision": 1.0,
                            "recall": 0.3968253968253968,
                            "f1": 0.5681818181818182,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6031746031746031,
                            "true_positive_rate": 0.3968253968253968
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3968253968253968,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3968253968253968,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5681818181818182,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6031746031746031,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3968253968253968,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 20,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.31746031746031744,
                            "precision": 1.0,
                            "recall": 0.31746031746031744,
                            "f1": 0.4819277108433735,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6825396825396826,
                            "true_positive_rate": 0.31746031746031744
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.31746031746031744,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.31746031746031744,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4819277108433735,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6825396825396826,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.31746031746031744,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 8,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.12698412698412698,
                            "precision": 1.0,
                            "recall": 0.12698412698412698,
                            "f1": 0.22535211267605634,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.873015873015873,
                            "true_positive_rate": 0.12698412698412698
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.12698412698412698,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.12698412698412698,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.22535211267605634,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.873015873015873,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.12698412698412698,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 5,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.07936507936507936,
                            "precision": 1.0,
                            "recall": 0.07936507936507936,
                            "f1": 0.14705882352941177,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.9206349206349206,
                            "true_positive_rate": 0.07936507936507936
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.07936507936507936,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.07936507936507936,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.14705882352941177,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.9206349206349206,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.07936507936507936,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 63,
                        "prediction_error_num": 10,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": 0.15873015873015872,
                            "precision": 1.0,
                            "recall": 0.15873015873015872,
                            "f1": 0.273972602739726,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8412698412698413,
                            "true_positive_rate": 0.15873015873015872
                        }
                    },
                    "average": {
                        "total_num": 63,
                        "gold_error_num": 63,
                        "metrics": {
                            "accuracy": {
                                "average": 0.15873015873015872,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.15873015873015872,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.273972602739726,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8412698412698413,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.15873015873015872,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.5066137566137565,
                            "stdev": 0.31881051057543436
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5066137566137565,
                            "stdev": 0.31881051057543436
                        },
                        "f1": {
                            "average": 0.6121581340170387,
                            "stdev": 0.28909876553691777
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4933862433862433,
                            "stdev": 0.3188105105754344
                        },
                        "true_positive_rate": {
                            "average": 0.5066137566137565,
                            "stdev": 0.31881051057543436
                        }
                    }
                }
            },
            "initial_model=meta-llama/Llama-2-70b-chat-hf": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 59,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.8082191780821918,
                            "precision": 1.0,
                            "recall": 0.8082191780821918,
                            "f1": 0.8939393939393939,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.1917808219178082,
                            "true_positive_rate": 0.8082191780821918
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8082191780821918,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8082191780821918,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8939393939393939,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.1917808219178082,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8082191780821918,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 62,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.8493150684931506,
                            "precision": 1.0,
                            "recall": 0.8493150684931506,
                            "f1": 0.9185185185185185,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.1506849315068493,
                            "true_positive_rate": 0.8493150684931506
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8493150684931506,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8493150684931506,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9185185185185185,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.1506849315068493,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8493150684931506,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 72,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.9863013698630136,
                            "precision": 1.0,
                            "recall": 0.9863013698630136,
                            "f1": 0.993103448275862,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0136986301369863,
                            "true_positive_rate": 0.9863013698630136
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9863013698630136,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.9863013698630136,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.993103448275862,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0136986301369863,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9863013698630136,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 27,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.3698630136986301,
                            "precision": 1.0,
                            "recall": 0.3698630136986301,
                            "f1": 0.54,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6301369863013698,
                            "true_positive_rate": 0.3698630136986301
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3698630136986301,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3698630136986301,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.54,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6301369863013698,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3698630136986301,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 44,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.6027397260273972,
                            "precision": 1.0,
                            "recall": 0.6027397260273972,
                            "f1": 0.7521367521367521,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.3972602739726027,
                            "true_positive_rate": 0.6027397260273972
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6027397260273972,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6027397260273972,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7521367521367521,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.3972602739726027,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6027397260273972,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 20,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.273972602739726,
                            "precision": 1.0,
                            "recall": 0.273972602739726,
                            "f1": 0.43010752688172044,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.726027397260274,
                            "true_positive_rate": 0.273972602739726
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.273972602739726,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.273972602739726,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.43010752688172044,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.726027397260274,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.273972602739726,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 28,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.3835616438356164,
                            "precision": 1.0,
                            "recall": 0.3835616438356164,
                            "f1": 0.5544554455445545,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6164383561643836,
                            "true_positive_rate": 0.3835616438356164
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3835616438356164,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3835616438356164,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5544554455445545,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6164383561643836,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3835616438356164,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 17,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.2328767123287671,
                            "precision": 1.0,
                            "recall": 0.2328767123287671,
                            "f1": 0.37777777777777777,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7671232876712328,
                            "true_positive_rate": 0.2328767123287671
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.2328767123287671,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.2328767123287671,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.37777777777777777,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7671232876712328,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.2328767123287671,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 23,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.3150684931506849,
                            "precision": 1.0,
                            "recall": 0.3150684931506849,
                            "f1": 0.4791666666666667,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.684931506849315,
                            "true_positive_rate": 0.3150684931506849
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3150684931506849,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3150684931506849,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4791666666666667,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.684931506849315,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3150684931506849,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 34,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.4657534246575342,
                            "precision": 1.0,
                            "recall": 0.4657534246575342,
                            "f1": 0.6355140186915887,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5342465753424658,
                            "true_positive_rate": 0.4657534246575342
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.4657534246575342,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.4657534246575342,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6355140186915887,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5342465753424658,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.4657534246575342,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 24,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.3287671232876712,
                            "precision": 1.0,
                            "recall": 0.3287671232876712,
                            "f1": 0.4948453608247423,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6712328767123288,
                            "true_positive_rate": 0.3287671232876712
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3287671232876712,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3287671232876712,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4948453608247423,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6712328767123288,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3287671232876712,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 73,
                        "prediction_error_num": 46,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": 0.6301369863013698,
                            "precision": 1.0,
                            "recall": 0.6301369863013698,
                            "f1": 0.773109243697479,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.3698630136986301,
                            "true_positive_rate": 0.6301369863013698
                        }
                    },
                    "average": {
                        "total_num": 73,
                        "gold_error_num": 73,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6301369863013698,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6301369863013698,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.773109243697479,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.3698630136986301,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6301369863013698,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.5205479452054794,
                            "stdev": 0.24040998321622248
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.5205479452054794,
                            "stdev": 0.24040998321622248
                        },
                        "f1": {
                            "average": 0.6535561794129213,
                            "stdev": 0.19830907639757495
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.4794520547945205,
                            "stdev": 0.24040998321622253
                        },
                        "true_positive_rate": {
                            "average": 0.5205479452054794,
                            "stdev": 0.24040998321622248
                        }
                    }
                }
            }
        }
    },
    "answerability_classification": {
        "Reasoning Correctness": {
            "initial_model=gpt-4-0613": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 24,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.7741935483870968,
                            "precision": 1.0,
                            "recall": 0.7741935483870968,
                            "f1": 0.8727272727272727,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.22580645161290322,
                            "true_positive_rate": 0.7741935483870968
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7741935483870968,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7741935483870968,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8727272727272727,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.22580645161290322,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7741935483870968,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 27,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.8709677419354839,
                            "precision": 1.0,
                            "recall": 0.8709677419354839,
                            "f1": 0.9310344827586207,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.12903225806451613,
                            "true_positive_rate": 0.8709677419354839
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8709677419354839,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8709677419354839,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9310344827586207,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.12903225806451613,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8709677419354839,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 1.0,
                            "precision": 1.0,
                            "recall": 1.0,
                            "f1": 1.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 1.0
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 24,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.7741935483870968,
                            "precision": 1.0,
                            "recall": 0.7741935483870968,
                            "f1": 0.8727272727272727,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.22580645161290322,
                            "true_positive_rate": 0.7741935483870968
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7741935483870968,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7741935483870968,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8727272727272727,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.22580645161290322,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7741935483870968,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 12,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.3870967741935484,
                            "precision": 1.0,
                            "recall": 0.3870967741935484,
                            "f1": 0.5581395348837209,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6129032258064516,
                            "true_positive_rate": 0.3870967741935484
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3870967741935484,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3870967741935484,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5581395348837209,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6129032258064516,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3870967741935484,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 19,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.6129032258064516,
                            "precision": 1.0,
                            "recall": 0.6129032258064516,
                            "f1": 0.76,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.3870967741935484,
                            "true_positive_rate": 0.6129032258064516
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6129032258064516,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6129032258064516,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.76,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.3870967741935484,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6129032258064516,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 8,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.25806451612903225,
                            "precision": 1.0,
                            "recall": 0.25806451612903225,
                            "f1": 0.41025641025641024,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7419354838709677,
                            "true_positive_rate": 0.25806451612903225
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.25806451612903225,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25806451612903225,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.41025641025641024,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7419354838709677,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.25806451612903225,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 7,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.22580645161290322,
                            "precision": 1.0,
                            "recall": 0.22580645161290322,
                            "f1": 0.3684210526315789,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7741935483870968,
                            "true_positive_rate": 0.22580645161290322
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.22580645161290322,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.22580645161290322,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.3684210526315789,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7741935483870968,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.22580645161290322,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 5,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.16129032258064516,
                            "precision": 1.0,
                            "recall": 0.16129032258064516,
                            "f1": 0.2777777777777778,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8387096774193549,
                            "true_positive_rate": 0.16129032258064516
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.16129032258064516,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.16129032258064516,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.2777777777777778,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8387096774193549,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.16129032258064516,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 8,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.25806451612903225,
                            "precision": 1.0,
                            "recall": 0.25806451612903225,
                            "f1": 0.41025641025641024,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7419354838709677,
                            "true_positive_rate": 0.25806451612903225
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.25806451612903225,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25806451612903225,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.41025641025641024,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7419354838709677,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.25806451612903225,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 4,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.12903225806451613,
                            "precision": 1.0,
                            "recall": 0.12903225806451613,
                            "f1": 0.22857142857142856,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8709677419354839,
                            "true_positive_rate": 0.12903225806451613
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.12903225806451613,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.12903225806451613,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.22857142857142856,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8709677419354839,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.12903225806451613,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 31,
                        "prediction_error_num": 8,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": 0.25806451612903225,
                            "precision": 1.0,
                            "recall": 0.25806451612903225,
                            "f1": 0.41025641025641024,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7419354838709677,
                            "true_positive_rate": 0.25806451612903225
                        }
                    },
                    "average": {
                        "total_num": 31,
                        "gold_error_num": 31,
                        "metrics": {
                            "accuracy": {
                                "average": 0.25806451612903225,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25806451612903225,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.41025641025641024,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7419354838709677,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.25806451612903225,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.4758064516129031,
                            "stdev": 0.29714942384292764
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.4758064516129031,
                            "stdev": 0.29714942384292764
                        },
                        "f1": {
                            "average": 0.5916806710705753,
                            "stdev": 0.2658773159537768
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.5241935483870969,
                            "stdev": 0.29714942384292764
                        },
                        "true_positive_rate": {
                            "average": 0.4758064516129031,
                            "stdev": 0.29714942384292764
                        }
                    }
                }
            },
            "initial_model=meta-llama/Llama-2-70b-chat-hf": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 24,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.3116883116883117,
                            "precision": 1.0,
                            "recall": 0.3116883116883117,
                            "f1": 0.4752475247524752,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6883116883116883,
                            "true_positive_rate": 0.3116883116883117
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3116883116883117,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3116883116883117,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4752475247524752,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6883116883116883,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3116883116883117,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 53,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.6883116883116883,
                            "precision": 1.0,
                            "recall": 0.6883116883116883,
                            "f1": 0.8153846153846154,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.3116883116883117,
                            "true_positive_rate": 0.6883116883116883
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6883116883116883,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6883116883116883,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8153846153846154,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.3116883116883117,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6883116883116883,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 75,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.974025974025974,
                            "precision": 1.0,
                            "recall": 0.974025974025974,
                            "f1": 0.9868421052631579,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.025974025974025976,
                            "true_positive_rate": 0.974025974025974
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.974025974025974,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.974025974025974,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9868421052631579,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.025974025974025976,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.974025974025974,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 35,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.45454545454545453,
                            "precision": 1.0,
                            "recall": 0.45454545454545453,
                            "f1": 0.625,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5454545454545454,
                            "true_positive_rate": 0.45454545454545453
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.45454545454545453,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.45454545454545453,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.625,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5454545454545454,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.45454545454545453,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 4,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.05194805194805195,
                            "precision": 1.0,
                            "recall": 0.05194805194805195,
                            "f1": 0.09876543209876543,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.948051948051948,
                            "true_positive_rate": 0.05194805194805195
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.05194805194805195,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.05194805194805195,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.09876543209876543,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.948051948051948,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.05194805194805195,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 22,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.2857142857142857,
                            "precision": 1.0,
                            "recall": 0.2857142857142857,
                            "f1": 0.4444444444444444,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7142857142857143,
                            "true_positive_rate": 0.2857142857142857
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.2857142857142857,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.2857142857142857,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4444444444444444,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7142857142857143,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.2857142857142857,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 9,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.11688311688311688,
                            "precision": 1.0,
                            "recall": 0.11688311688311688,
                            "f1": 0.20930232558139536,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8831168831168831,
                            "true_positive_rate": 0.11688311688311688
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.11688311688311688,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.11688311688311688,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.20930232558139536,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8831168831168831,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.11688311688311688,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 1,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.012987012987012988,
                            "precision": 1.0,
                            "recall": 0.012987012987012988,
                            "f1": 0.02564102564102564,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.987012987012987,
                            "true_positive_rate": 0.012987012987012988
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.012987012987012988,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.012987012987012988,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.02564102564102564,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.987012987012987,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.012987012987012988,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 7,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.09090909090909091,
                            "precision": 1.0,
                            "recall": 0.09090909090909091,
                            "f1": 0.16666666666666666,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.9090909090909091,
                            "true_positive_rate": 0.09090909090909091
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.09090909090909091,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.09090909090909091,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.16666666666666666,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.9090909090909091,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.09090909090909091,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 15,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.19480519480519481,
                            "precision": 1.0,
                            "recall": 0.19480519480519481,
                            "f1": 0.32608695652173914,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8051948051948052,
                            "true_positive_rate": 0.19480519480519481
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.19480519480519481,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.19480519480519481,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.32608695652173914,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8051948051948052,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.19480519480519481,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 40,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.5194805194805194,
                            "precision": 1.0,
                            "recall": 0.5194805194805194,
                            "f1": 0.6837606837606838,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.4805194805194805,
                            "true_positive_rate": 0.5194805194805194
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5194805194805194,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5194805194805194,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.6837606837606838,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.4805194805194805,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5194805194805194,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 57,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.7402597402597403,
                            "precision": 1.0,
                            "recall": 0.7402597402597403,
                            "f1": 0.8507462686567164,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.2597402597402597,
                            "true_positive_rate": 0.7402597402597403
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7402597402597403,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7402597402597403,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8507462686567164,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2597402597402597,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7402597402597403,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.37012987012987014,
                            "stdev": 0.29503204651779763
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.37012987012987014,
                            "stdev": 0.29503204651779763
                        },
                        "f1": {
                            "average": 0.47565733739764043,
                            "stdev": 0.3051440312668515
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.6298701298701298,
                            "stdev": 0.29503204651779763
                        },
                        "true_positive_rate": {
                            "average": 0.37012987012987014,
                            "stdev": 0.29503204651779763
                        }
                    }
                }
            }
        },
        "Parameterized Knowledge": {
            "initial_model=gpt-4-0613": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 44,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.7543859649122807,
                            "precision": 0.9772727272727273,
                            "recall": 0.7678571428571429,
                            "f1": 0.86,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.017543859649122806,
                            "false_negative_rate": 0.22807017543859648,
                            "true_positive_rate": 0.7543859649122807
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7543859649122807,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 0.9772727272727273,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7678571428571429,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.86,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.22807017543859648,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7543859649122807,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 51,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.8771929824561403,
                            "precision": 0.9803921568627451,
                            "recall": 0.8928571428571429,
                            "f1": 0.9345794392523364,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.017543859649122806,
                            "false_negative_rate": 0.10526315789473684,
                            "true_positive_rate": 0.8771929824561403
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.8771929824561403,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 0.9803921568627451,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.8928571428571429,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9345794392523364,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.10526315789473684,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.8771929824561403,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.9824561403508771,
                            "precision": 0.9824561403508771,
                            "recall": 1.0,
                            "f1": 0.9911504424778761,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.017543859649122806,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 0.9824561403508771
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.9824561403508771,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 0.9824561403508771,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.9911504424778761,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.9824561403508771,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 40,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.6842105263157895,
                            "precision": 0.975,
                            "recall": 0.6964285714285714,
                            "f1": 0.8125,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.017543859649122806,
                            "false_negative_rate": 0.2982456140350877,
                            "true_positive_rate": 0.6842105263157895
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6842105263157895,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 0.975,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6964285714285714,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8125,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.2982456140350877,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6842105263157895,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 18,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.3333333333333333,
                            "precision": 1.0,
                            "recall": 0.32142857142857145,
                            "f1": 0.4864864864864865,
                            "true_negative_rate": 0.017543859649122806,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6666666666666666,
                            "true_positive_rate": 0.3157894736842105
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3333333333333333,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.32142857142857145,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4864864864864865,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6666666666666666,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3157894736842105,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 39,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.6666666666666666,
                            "precision": 0.9743589743589743,
                            "recall": 0.6785714285714286,
                            "f1": 0.8,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.017543859649122806,
                            "false_negative_rate": 0.3157894736842105,
                            "true_positive_rate": 0.6666666666666666
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.6666666666666666,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 0.9743589743589743,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.6785714285714286,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.3157894736842105,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.6666666666666666,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 4,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.08771929824561403,
                            "precision": 1.0,
                            "recall": 0.07142857142857142,
                            "f1": 0.13333333333333333,
                            "true_negative_rate": 0.017543859649122806,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.9122807017543859,
                            "true_positive_rate": 0.07017543859649122
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.08771929824561403,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.07142857142857142,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.13333333333333333,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.9122807017543859,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.07017543859649122,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 6,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.12280701754385964,
                            "precision": 1.0,
                            "recall": 0.10714285714285714,
                            "f1": 0.1935483870967742,
                            "true_negative_rate": 0.017543859649122806,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8771929824561403,
                            "true_positive_rate": 0.10526315789473684
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.12280701754385964,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.10714285714285714,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.1935483870967742,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8771929824561403,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.10526315789473684,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 14,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.2631578947368421,
                            "precision": 1.0,
                            "recall": 0.25,
                            "f1": 0.4,
                            "true_negative_rate": 0.017543859649122806,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7368421052631579,
                            "true_positive_rate": 0.24561403508771928
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.2631578947368421,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7368421052631579,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.24561403508771928,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 12,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.22807017543859648,
                            "precision": 1.0,
                            "recall": 0.21428571428571427,
                            "f1": 0.35294117647058826,
                            "true_negative_rate": 0.017543859649122806,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.7719298245614035,
                            "true_positive_rate": 0.21052631578947367
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.22807017543859648,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.21428571428571427,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.35294117647058826,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.7719298245614035,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.21052631578947367,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 4,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.08771929824561403,
                            "precision": 1.0,
                            "recall": 0.07142857142857142,
                            "f1": 0.13333333333333333,
                            "true_negative_rate": 0.017543859649122806,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.9122807017543859,
                            "true_positive_rate": 0.07017543859649122
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.08771929824561403,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.07142857142857142,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.13333333333333333,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.9122807017543859,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.07017543859649122,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 57,
                        "prediction_error_num": 7,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": 0.14035087719298245,
                            "precision": 1.0,
                            "recall": 0.125,
                            "f1": 0.2222222222222222,
                            "true_negative_rate": 0.017543859649122806,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8596491228070176,
                            "true_positive_rate": 0.12280701754385964
                        }
                    },
                    "average": {
                        "total_num": 57,
                        "gold_error_num": 56,
                        "metrics": {
                            "accuracy": {
                                "average": 0.14035087719298245,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.125,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.2222222222222222,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.017543859649122806,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8596491228070176,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.12280701754385964,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.435672514619883,
                            "stdev": 0.31900839402717857
                        },
                        "precision": {
                            "average": 0.990789999903777,
                            "stdev": 0.01108060025509205
                        },
                        "recall": {
                            "average": 0.43303571428571425,
                            "stdev": 0.33305087416025736
                        },
                        "f1": {
                            "average": 0.5266745683894126,
                            "stdev": 0.3176183232768438
                        },
                        "true_negative_rate": {
                            "average": 0.01023391812865497,
                            "stdev": 0.008649239448976047
                        },
                        "false_positive_rate": {
                            "average": 0.007309941520467836,
                            "stdev": 0.008649239448976047
                        },
                        "false_negative_rate": {
                            "average": 0.5570175438596491,
                            "stdev": 0.3272078763679721
                        },
                        "true_positive_rate": {
                            "average": 0.425438596491228,
                            "stdev": 0.3272078763679721
                        }
                    }
                }
            },
            "initial_model=meta-llama/Llama-2-70b-chat-hf": {
                "baseline_model=google/gemma-7b-it": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 28,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.36363636363636365,
                            "precision": 1.0,
                            "recall": 0.36363636363636365,
                            "f1": 0.5333333333333333,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6363636363636364,
                            "true_positive_rate": 0.36363636363636365
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.36363636363636365,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.36363636363636365,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5333333333333333,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6363636363636364,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.36363636363636365,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-13b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 58,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.7532467532467533,
                            "precision": 1.0,
                            "recall": 0.7532467532467533,
                            "f1": 0.8592592592592593,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.24675324675324675,
                            "true_positive_rate": 0.7532467532467533
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.7532467532467533,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.7532467532467533,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.8592592592592593,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.24675324675324675,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.7532467532467533,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=meta-llama/Llama-2-70b-chat-hf": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 1.0,
                            "precision": 1.0,
                            "recall": 1.0,
                            "f1": 1.0,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.0,
                            "true_positive_rate": 1.0
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 1.0,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mistral-7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 35,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.45454545454545453,
                            "precision": 1.0,
                            "recall": 0.45454545454545453,
                            "f1": 0.625,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.5454545454545454,
                            "true_positive_rate": 0.45454545454545453
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.45454545454545453,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.45454545454545453,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.625,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.5454545454545454,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.45454545454545453,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=mistralai/Mixtral-8x7B-Instruct-v0.1": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 10,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.12987012987012986,
                            "precision": 1.0,
                            "recall": 0.12987012987012986,
                            "f1": 0.22988505747126436,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8701298701298701,
                            "true_positive_rate": 0.12987012987012986
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.12987012987012986,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.12987012987012986,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.22988505747126436,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8701298701298701,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.12987012987012986,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-14B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 24,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.3116883116883117,
                            "precision": 1.0,
                            "recall": 0.3116883116883117,
                            "f1": 0.4752475247524752,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6883116883116883,
                            "true_positive_rate": 0.3116883116883117
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.3116883116883117,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.3116883116883117,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.4752475247524752,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6883116883116883,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.3116883116883117,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=Qwen/Qwen1.5-72B-Chat": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 11,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.14285714285714285,
                            "precision": 1.0,
                            "recall": 0.14285714285714285,
                            "f1": 0.25,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.8571428571428571,
                            "true_positive_rate": 0.14285714285714285
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.14285714285714285,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.14285714285714285,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.25,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.8571428571428571,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.14285714285714285,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-3.5-turbo-0125": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 2,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.025974025974025976,
                            "precision": 1.0,
                            "recall": 0.025974025974025976,
                            "f1": 0.05063291139240506,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.974025974025974,
                            "true_positive_rate": 0.025974025974025976
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.025974025974025976,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.025974025974025976,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.05063291139240506,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.974025974025974,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.025974025974025976,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=models/gemini-1.0-pro-001": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 2,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.025974025974025976,
                            "precision": 1.0,
                            "recall": 0.025974025974025976,
                            "f1": 0.05063291139240506,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.974025974025974,
                            "true_positive_rate": 0.025974025974025976
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.025974025974025976,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.025974025974025976,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.05063291139240506,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.974025974025974,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.025974025974025976,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=claude-3-opus-20240229": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 4,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.05194805194805195,
                            "precision": 1.0,
                            "recall": 0.05194805194805195,
                            "f1": 0.09876543209876543,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.948051948051948,
                            "true_positive_rate": 0.05194805194805195
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.05194805194805195,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.05194805194805195,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.09876543209876543,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.948051948051948,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.05194805194805195,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0613": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 29,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.37662337662337664,
                            "precision": 1.0,
                            "recall": 0.37662337662337664,
                            "f1": 0.5471698113207547,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.6233766233766234,
                            "true_positive_rate": 0.37662337662337664
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.37662337662337664,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.37662337662337664,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.5471698113207547,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.6233766233766234,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.37662337662337664,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "baseline_model=gpt-4-0125-preview": {
                    "cot_instruction_prompt": {
                        "total_num": 77,
                        "prediction_error_num": 43,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": 0.5584415584415584,
                            "precision": 1.0,
                            "recall": 0.5584415584415584,
                            "f1": 0.7166666666666667,
                            "true_negative_rate": 0.0,
                            "false_positive_rate": 0.0,
                            "false_negative_rate": 0.44155844155844154,
                            "true_positive_rate": 0.5584415584415584
                        }
                    },
                    "average": {
                        "total_num": 77,
                        "gold_error_num": 77,
                        "metrics": {
                            "accuracy": {
                                "average": 0.5584415584415584,
                                "stdev": 0.0
                            },
                            "precision": {
                                "average": 1.0,
                                "stdev": 0.0
                            },
                            "recall": {
                                "average": 0.5584415584415584,
                                "stdev": 0.0
                            },
                            "f1": {
                                "average": 0.7166666666666667,
                                "stdev": 0.0
                            },
                            "true_negative_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_positive_rate": {
                                "average": 0.0,
                                "stdev": 0.0
                            },
                            "false_negative_rate": {
                                "average": 0.44155844155844154,
                                "stdev": 0.0
                            },
                            "true_positive_rate": {
                                "average": 0.5584415584415584,
                                "stdev": 0.0
                            }
                        }
                    }
                },
                "average": {
                    "metrics": {
                        "accuracy": {
                            "average": 0.3495670995670996,
                            "stdev": 0.2932620871326619
                        },
                        "precision": {
                            "average": 1.0,
                            "stdev": 0.0
                        },
                        "recall": {
                            "average": 0.3495670995670996,
                            "stdev": 0.2932620871326619
                        },
                        "f1": {
                            "average": 0.4530494089739441,
                            "stdev": 0.30542947527227343
                        },
                        "true_negative_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_positive_rate": {
                            "average": 0.0,
                            "stdev": 0.0
                        },
                        "false_negative_rate": {
                            "average": 0.6504329004329005,
                            "stdev": 0.2932620871326619
                        },
                        "true_positive_rate": {
                            "average": 0.3495670995670996,
                            "stdev": 0.2932620871326619
                        }
                    }
                }
            }
        }
    }
}